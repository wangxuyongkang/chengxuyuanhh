<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.0.5 (458014)"/><meta name="altitude" content="36"/><meta name="author" content="李居豪"/><meta name="created" content="2019-05-29 13:55:59 +0000"/><meta name="latitude" content="39.63155600945159"/><meta name="longitude" content="116.0504260503393"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2019-05-29 14:57:55 +0000"/><meta name="content-class" content="yinxiang.markdown"/><title>24  Scrapy CrawlSpiders介绍和使用</title></head><body><div style="font-size: 14px; margin: 0; padding: 0; width: 100%;"><h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;">scrapy通用爬虫（CrawlSpider）</h3>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">CrawlSpider</strong>它是Spider的派生类，Spider类的设计原则是只爬取start_url列表中的网页，而<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">CrawlSpider</strong>类定义了一些规则<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">Rule</strong>来提供<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">跟进链接</strong>的方便的机制，从爬取的网页结果中获取链接并继续爬取的工作．</p>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">源码参考</strong></h3>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">class CrawlSpider(Spider):
    rules = ()
    def __init__(self, *a, **kw):
        super(CrawlSpider, self).__init__(*a, **kw)
        self._compile_rules()

    #首先调用parse()来处理start_urls中返回的response对象
    #parse()则将这些response对象传递给了_parse_response()函数处理，并设置回调函数为parse_start_url()
    #设置了跟进标志位True
    #parse将返回item和跟进了的Request对象    
    def parse(self, response):
        return self._parse_response(response, self.parse_start_url, cb_kwargs={}, follow=True)

    #处理start_url中返回的response，需要重写
    def parse_start_url(self, response):
        return []

    def process_results(self, response, results):
        return results

    #从response中抽取符合任一用户定义'规则'的链接，并构造成Resquest对象返回
    def _requests_to_follow(self, response):
        if not isinstance(response, HtmlResponse):
            return
        seen = set()
        #抽取之内的所有链接，只要通过任意一个'规则'，即表示合法
        for n, rule in enumerate(self._rules):
            links = [l for l in rule.link_extractor.extract_links(response) if l not in seen]
            #使用用户指定的process_links处理每个连接
            if links and rule.process_links:
                links = rule.process_links(links)
            #将链接加入seen集合，为每个链接生成Request对象，并设置回调函数为_repsonse_downloaded()
            for link in links:
                seen.add(link)
                #构造Request对象，并将Rule规则中定义的回调函数作为这个Request对象的回调函数
                r = Request(url=link.url, callback=self._response_downloaded)
                r.meta.update(rule=n, link_text=link.text)
                #对每个Request调用process_request()函数。该函数默认为indentify，即不做任何处理，直接返回该Request.
                yield rule.process_request(r)

    #处理通过rule提取出的连接，并返回item以及request
    def _response_downloaded(self, response):
        rule = self._rules[response.meta['rule']]
        return self._parse_response(response, rule.callback, rule.cb_kwargs, rule.follow)

    #解析response对象，会用callback解析处理他，并返回request或Item对象
    def _parse_response(self, response, callback, cb_kwargs, follow=True):
        #首先判断是否设置了回调函数。（该回调函数可能是rule中的解析函数，也可能是 parse_start_url函数）
        #如果设置了回调函数（parse_start_url()），那么首先用parse_start_url()处理response对象，
        #然后再交给process_results处理。返回cb_res的一个列表
        if callback:
            #如果是parse调用的，则会解析成Request对象
            #如果是rule callback，则会解析成Item
            cb_res = callback(response, **cb_kwargs) or ()
            cb_res = self.process_results(response, cb_res)
            for requests_or_item in iterate_spider_output(cb_res):
                yield requests_or_item

        #如果需要跟进，那么使用定义的Rule规则提取并返回这些Request对象
        if follow and self._follow_links:
            #返回每个Request对象
            for request_or_item in self._requests_to_follow(response):
                yield request_or_item

    def _compile_rules(self):
        def get_method(method):
            if callable(method):
                return method
            elif isinstance(method, basestring):
                return getattr(self, method, None)

        self._rules = [copy.copy(r) for r in self.rules]
        for rule in self._rules:
            rule.callback = get_method(rule.callback)
            rule.process_links = get_method(rule.process_links)
            rule.process_request = get_method(rule.process_request)

    def set_crawler(self, crawler):
        super(CrawlSpider, self).set_crawler(crawler)
        self._follow_links = crawler.settings.getbool('CRAWLSPIDER_FOLLOW_LINKS', True)
</code></pre>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;">创建爬虫文件</h3>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">通过下面的命令可以快速创建 CrawlSpider模板 的代码：</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">scrapy genspider -t crawl 爬虫文件 域名
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">CrawlSpider</strong>继承于<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">Spider</strong>类，除了继承过来的属性外（name、allow_domains），还提供了新的属性和方法:</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">class XcfcrawlspiderSpider(CrawlSpider):
    #爬虫名称
    name = 'xcfCrawlSpider'
    #设置允许爬取的域
    allowed_domains = ['xiachufang.com']
    #设置起始的url
    start_urls = ['http://www.xiachufang.com/category/']
    rules = (
        Rule(
            LinkExtractor(allow=r'.*?/category/\d+/'),
            callback='parse_item',
            follow=True,
            process_links='check_category_url'
        ),
    )
</code></pre>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">rules</strong></h3>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">CrawlSpider</strong>使用<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">rules</strong>属性来决定爬虫的爬取规则，并将匹配后的url请求提交给引擎,完成后续的爬取工作。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">在<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">rules</strong>中包含一个或多个<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">Rule</strong>对象，每个Rule对爬取网站的动作定义了某种特定操作，比如提取当前相应内容里的特定链接，是否对提取的链接跟进爬取，对提交的请求设置回调函数等。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">注意:</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">如果多个rule匹配了相同的链接，则根据规则在本集合中被定义的顺序，第一个会被使用</strong>。</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">class scrapy.spiders.Rule(
        link_extractor,
        callback = None,
        cb_kwargs = None,
        follow = None,
        process_links = None,
        process_request = None
)
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">link_extractor</strong>：是一个Link Extractor对象，用于定义需要提取的链接。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">callback</strong>： 从link_extractor中每获取到链接得到Responses时，会调用参数所指定的值作为回调函数，该回调函数接收一个response作为其一个参数。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">follow</strong>：是一个布尔(boolean)值，指定了根据该规则从response提取的链接是否需要跟进。<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">如果callback为None，follow 默认设置为True ，否则默认为False。</strong></p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">process_links</strong>：指定spider中哪个的函数将会被调用，从link_extractor中获取到链接列表时将会调用该函数。该方法主要用来过滤。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">process_request</strong>：指定处理函数，根据该Rule提取到的每个Request时，该函数将会被调用，可以对Request进行处理，该函数必须返回Request或者None</p>
</li>
</ul>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">注意：<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">当编写爬虫规则时，避免使用parse作为回调函数。由于CrawlSpider使用parse方法来实现其逻辑，如果覆盖了 parse方法，crawl spider将会运行失败</strong>。</p>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">LinkExtractors</strong></h4>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">class scrapy.linkextractors.LinkExtractor
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">LinkExtractors 的目的很简单: <strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">提取链接</strong>｡</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">每个LinkExtractor有唯一的公共方法是 <strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">extract_links()</strong>，它接收一个 Response 对象，并返回一个 <strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">scrapy.link.Link</strong> 对象。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">LinkExtractors要实例化一次，并且 extract_links 方法会根据不同的 response 调用多次提取链接｡</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">class scrapy.linkextractors.LinkExtractor(
    allow = (),
    deny = (),
    allow_domains = (),
    deny_domains = (),
    deny_extensions = None,
    restrict_xpaths = (),
    tags = ('a','area'),
    attrs = ('href'),
    canonicalize = True,
    unique = True,
    process_value = None
)
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">主要参数：</p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">allow：满足括号中“正则表达式”的URL会被提取，如果为空，则全部匹配。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">deny：满足括号中“正则表达式”的URL一定不提取（优先级高于allow）。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">allow_domains：会提取的链接的domains。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">deny_domains：一定不会被提取链接的domains。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">restrict_xpaths：使用xpath表达式，和allow共同作用过滤链接。</p>
</li>
</ul>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">爬取规则(Crawling rules)</strong></h3>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">下厨房案例</strong></h3>
<ol style="line-height: 160%; box-sizing: content-box; display: block; padding-left: 30px; margin: 6px 0 10px; color: #333; list-style-type: decimal;">
<li style="line-height: 160%; box-sizing: content-box;">可以先创建一个虚拟环境</li>
<li style="line-height: 160%; box-sizing: content-box;">进入指定目录，创建爬虫项目</li>
</ol>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">上面创建虚拟环境的的步骤这里不在讲解，虚拟环境创建完毕后我们创建智联的爬虫项目</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">1.创建项目scrapy startproject xiachufang(项目名称)<br/>
2.进入spiders目录创建xiachufang爬虫文件<br/>
scrapy gen spider -t crawl xcfcrawlspider xiachufang.com<br/>
3.执行完成后使用scrapy list查看当前存在的spider爬虫文件</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">第一步：根据要爬取的网页确定需要保存的字段</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">Item.py:定义需要爬取的字段</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">class XiachufangItem(scrapy.Item):
    #图片链接
    coverImage = scrapy.Field()
    #名称
    title = scrapy.Field()
    #评分
    score = scrapy.Field()
    #多少人做过
    doitnum = scrapy.Field()
    #发布人
    author = scrapy.Field()
    #用料
    used = scrapy.Field()
    #做法
    methodway = scrapy.Field()

    def insert_data_to_db(self,dataDict):
        sql = """
        INSERT INTO caipu (%s)
        VALUES (%s)
        """ % (','.join(dataDict.keys()),','.join(['%s']*len(dataDict)))

        data = list(dataDict.values())

        return sql,data
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">第二步：编写爬虫类</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">LinkExtractor实例对象</strong></p>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;">根据需要提取的页面的url来设置需要提取的规则</h4>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">LinkExtractor方法中的常用的参数</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">allow : LinkExtractor对象最重要的参数之一，这是一个正则表达式，必须要匹配这个正则表达式(或正则表达式列表)的URL才会被提取，如果没有给出(或为空), 它会匹配所有的链接｡</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">deny : 用法同allow，只不过与这个正则表达式匹配的URL不会被提取)｡它的优先级高于 - allow 的参数，如果没有给出(或None), 将不排除任何链接｡</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">allow_domains:包含了spider允许爬取的域名(domain)列表(list)</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">deny_domains=():包含了spider不允许爬取的域名(domain)列表(list)</p>
</li>
</ul>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">spider爬虫文件代码</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;"># -*- coding: utf-8 -*-
import scrapy
from scrapy.linkextractors import LinkExtractor
from scrapy.spiders import CrawlSpider, Rule
#通用爬虫提取到的连接会构建一个Link对象
from scrapy.link import Link
from xiachufang.items import XiachufangItem

#创建通用爬虫的命令：scrapy genspider -t crawl 爬虫名称　域

class XcfcrawlspiderSpider(CrawlSpider):
    #爬虫名称
    name = 'xcfCrawlSpider'
    #设置允许爬取的域
    allowed_domains = ['xiachufang.com']
    #设置起始的url
    start_urls = ['http://www.xiachufang.com/category/']

    # rules:是一个元组（列表）,里面存放的是规则Rule规则对象
    # 可以有多个规则

    #Rule:
    #LinkExtractor:设置提取规则
    #callback:设置回调函数（获取响应,解析数据）
    #follow:设置是否需要跟进

    rules = (
        #分类列表地址
        # http://www.xiachufang.com/category/40073/
        Rule(
            LinkExtractor(allow=r'.*?/category/\d+/'),
            callback='parse_item',
            follow=True,
            process_links='check_category_url'
        ),
        # 菜单详情地址,
        # http://www.xiachufang.com/recipe/1055105/
        # http://www.xiachufang.com/recipe/12137/
        # http://www.xiachufang.com/recipe/100147684/
        Rule(
            LinkExtractor(
                allow=r'.*?/recipe/\d+/',
            ),
            callback='parse_caipu_detail',
            follow=False,
        )
    )

    # def parse(self): 一定不能出现这个方法,因为crawlSpider使用了这个方法

    def parse_item(self, response):
        print('分类获取成功')
        print(response.status,response.url)

    def check_category_url(self,links):
        """
        可以在此方法做对规则提取的url构建成的的link对象做过滤处理
        :param links:
        :return:
        """
        print('===================',links,'===================')
        return links

    def parse_caipu_detail(self,response):
        """
        菜谱详情请求成功后的结果处理,从响应结果中提取目标数据
        :param response:
        :return:
        """
        print('详情获取成功')
        print(response.status,response.url)
        # 取出item
        item = XiachufangItem()
        # 图片链接
        item['coverImage'] = response.xpath('//div[@]/img/@src').extract_first('')
        # 名称
        item['title'] = ''.join(response.xpath('//h1[@]/text()').extract()).replace(' ','').replace('\n','')
        # 评分
        item['score'] = response.xpath('//div[@]/span[@]/text()').extract_first('')
        # 多少人做过
        item['doitnum'] = response.xpath('//div[@]/span[@]/text()').extract_first('')
        # 发布人
        item['author'] = response.xpath('//div[@]/a[1]/span/text()').extract_first('')
        # 获取用料的列表
        # 对吓：8只;对吓：8只;对吓：8只;对吓：8只;对吓：8只
        tr_list = response.css('div.ings tr')
        used_list = []
        for tr in tr_list:
            name = ''.join(tr.css('td.name ::text').extract()).replace('\n', '').replace(' ', '')
            value = ''.join(tr.css('td.unit ::text').extract()).replace('\n', '').replace(' ', '')
            if len(value) == 0:
                value = '若干'
            used_list.append(name + ':' + value)
        item['used'] = ';'.join(used_list)
        # 获取做法
        item['methodway'] = '-&gt;'.join(response.css('div.steps p.text ::text').extract())
        print(item)
        # yield item

</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">第三步：数据保存</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">pipelines管道文件</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">import pymysql

class XiachufangPipeline(object):

    def __init__(self,host,port,user,pwd,db,charset):

        self.client = pymysql.Connect(host,user,pwd,db,port,charset=charset)
        self.cursor = self.client.cursor()

    @classmethod
    def from_crawler(cls,crawler):
        host = crawler.settings['MYSQL_HOST']
        port = crawler.settings['MYSQL_PORT']
        user = crawler.settings['MYSQL_USER']
        pwd = crawler.settings['MYSQL_PWD']
        db = crawler.settings['MYSQL_DB']
        charset = crawler.settings['CHARSET']

        return cls(host,port,user,pwd,db,charset)


    def process_item(self, item, spider):

        sql,data = item.insert_data_to_db(dict(item))

        try:
            self.cursor.execute(sql,data)
            self.client.commit()
            print('插入成功')
        except Exception as err:
            print(err)
            self.client.rollback()

        return item

    def close_spider(self,spider):
        self.cursor.close()
        self.client.close()
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">第四步：settings相关设置</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">settings.py设置文件</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">settings里面设置相关参数
1.ROBOTSTXT_OBEY = False 设置是否遵守robot协议
2.DOWNLOAD_DELAY = 3 设置下载延时
3.设置全局的Header
DEFAULT_REQUEST_HEADERS = {
    'User-Agent':' Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:59.0) Gecko/20100101 Firefox/59.0',
}

4.激活pipelines数据处理管道

ITEM_PIPELINES = {
   'xiachufang.pipelines.XiachufangPipeline': 300,
}

#关于数据库的相关配置
MYSQL_HOST = '127.0.0.1'
MYSQL_PORT = 3306
MYSQL_USER = ''
MYSQL_PWD = ''
MYSQL_DB = ''
CHARSET = 'utf8'
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">第五步：运行程序</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">方式一</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">运行：
scrapy crawl xcfcrawlspider
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">方式二</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">编写main.py文件执行</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">import os,sys
from scrapy.cmdline import execute

sys.path.append(os.path.dirname(os.path.abspath(__file__)))
execute(['scrapy','crawl','xcfcrawlspider'])
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">注意：</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">#提取匹配的链接
page_lx = LinkExtractor(allow = ('匹配规则'))

rules = [
    #提取匹配,并使用spider的parse方法进行分析;并跟进链接(没有callback意味着follow默认为True)
    Rule(page_lx, callback = 'parse', follow = True)
]
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">这么写对吗？不对！千万记住 callback 千万不能写 parse，再次强调：由于CrawlSpider使用parse方法来实现其逻辑，如果覆盖了 parse方法，crawl spider将会运行失败。</strong></p>
<hr style="line-height: 160%; box-sizing: content-box; border-top: 1px solid #eee; margin: 16px 0;"/>
<h2 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 34px; border-bottom: 1px solid #dbdbdb; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">作业</strong></h2>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">1.使用通用爬虫完成<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">自如有家</strong>房源信息的提取<br/>
2.使用通用爬虫完成<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">起点中文网</strong>小说信息获取</p>
</div><center style="display:none !important;visibility:collapse !important;height:0 !important;white-space:nowrap;width:100%;overflow:hidden">%23%23%23%20scrapy%E9%80%9A%E7%94%A8%E7%88%AC%E8%99%AB%EF%BC%88CrawlSpider%EF%BC%89%0A%0A**CrawlSpider**%E5%AE%83%E6%98%AFSpider%E7%9A%84%E6%B4%BE%E7%94%9F%E7%B1%BB%EF%BC%8CSpider%E7%B1%BB%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%E6%98%AF%E5%8F%AA%E7%88%AC%E5%8F%96start_url%E5%88%97%E8%A1%A8%E4%B8%AD%E7%9A%84%E7%BD%91%E9%A1%B5%EF%BC%8C%E8%80%8C**CrawlSpider**%E7%B1%BB%E5%AE%9A%E4%B9%89%E4%BA%86%E4%B8%80%E4%BA%9B%E8%A7%84%E5%88%99**Rule**%E6%9D%A5%E6%8F%90%E4%BE%9B**%E8%B7%9F%E8%BF%9B%E9%93%BE%E6%8E%A5**%E7%9A%84%E6%96%B9%E4%BE%BF%E7%9A%84%E6%9C%BA%E5%88%B6%EF%BC%8C%E4%BB%8E%E7%88%AC%E5%8F%96%E7%9A%84%E7%BD%91%E9%A1%B5%E7%BB%93%E6%9E%9C%E4%B8%AD%E8%8E%B7%E5%8F%96%E9%93%BE%E6%8E%A5%E5%B9%B6%E7%BB%A7%E7%BB%AD%E7%88%AC%E5%8F%96%E7%9A%84%E5%B7%A5%E4%BD%9C%EF%BC%8E%0A%0A%23%23%23%20**%E6%BA%90%E7%A0%81%E5%8F%82%E8%80%83**%0A%60%60%60%0Aclass%20CrawlSpider(Spider)%3A%0A%20%20%20%20rules%20%3D%20()%0A%20%20%20%20def%20__init__(self%2C%20*a%2C%20**kw)%3A%0A%20%20%20%20%20%20%20%20super(CrawlSpider%2C%20self).__init__(*a%2C%20**kw)%0A%20%20%20%20%20%20%20%20self._compile_rules()%0A%0A%20%20%20%20%23%E9%A6%96%E5%85%88%E8%B0%83%E7%94%A8parse()%E6%9D%A5%E5%A4%84%E7%90%86start_urls%E4%B8%AD%E8%BF%94%E5%9B%9E%E7%9A%84response%E5%AF%B9%E8%B1%A1%0A%20%20%20%20%23parse()%E5%88%99%E5%B0%86%E8%BF%99%E4%BA%9Bresponse%E5%AF%B9%E8%B1%A1%E4%BC%A0%E9%80%92%E7%BB%99%E4%BA%86_parse_response()%E5%87%BD%E6%95%B0%E5%A4%84%E7%90%86%EF%BC%8C%E5%B9%B6%E8%AE%BE%E7%BD%AE%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E4%B8%BAparse_start_url()%0A%20%20%20%20%23%E8%AE%BE%E7%BD%AE%E4%BA%86%E8%B7%9F%E8%BF%9B%E6%A0%87%E5%BF%97%E4%BD%8DTrue%0A%20%20%20%20%23parse%E5%B0%86%E8%BF%94%E5%9B%9Eitem%E5%92%8C%E8%B7%9F%E8%BF%9B%E4%BA%86%E7%9A%84Request%E5%AF%B9%E8%B1%A1%20%20%20%20%0A%20%20%20%20def%20parse(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20return%20self._parse_response(response%2C%20self.parse_start_url%2C%20cb_kwargs%3D%7B%7D%2C%20follow%3DTrue)%0A%0A%20%20%20%20%23%E5%A4%84%E7%90%86start_url%E4%B8%AD%E8%BF%94%E5%9B%9E%E7%9A%84response%EF%BC%8C%E9%9C%80%E8%A6%81%E9%87%8D%E5%86%99%0A%20%20%20%20def%20parse_start_url(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20return%20%5B%5D%0A%0A%20%20%20%20def%20process_results(self%2C%20response%2C%20results)%3A%0A%20%20%20%20%20%20%20%20return%20results%0A%0A%20%20%20%20%23%E4%BB%8Eresponse%E4%B8%AD%E6%8A%BD%E5%8F%96%E7%AC%A6%E5%90%88%E4%BB%BB%E4%B8%80%E7%94%A8%E6%88%B7%E5%AE%9A%E4%B9%89'%E8%A7%84%E5%88%99'%E7%9A%84%E9%93%BE%E6%8E%A5%EF%BC%8C%E5%B9%B6%E6%9E%84%E9%80%A0%E6%88%90Resquest%E5%AF%B9%E8%B1%A1%E8%BF%94%E5%9B%9E%0A%20%20%20%20def%20_requests_to_follow(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20if%20not%20isinstance(response%2C%20HtmlResponse)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%20%20%20%20%20%20%20%20seen%20%3D%20set()%0A%20%20%20%20%20%20%20%20%23%E6%8A%BD%E5%8F%96%E4%B9%8B%E5%86%85%E7%9A%84%E6%89%80%E6%9C%89%E9%93%BE%E6%8E%A5%EF%BC%8C%E5%8F%AA%E8%A6%81%E9%80%9A%E8%BF%87%E4%BB%BB%E6%84%8F%E4%B8%80%E4%B8%AA'%E8%A7%84%E5%88%99'%EF%BC%8C%E5%8D%B3%E8%A1%A8%E7%A4%BA%E5%90%88%E6%B3%95%0A%20%20%20%20%20%20%20%20for%20n%2C%20rule%20in%20enumerate(self._rules)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20links%20%3D%20%5Bl%20for%20l%20in%20rule.link_extractor.extract_links(response)%20if%20l%20not%20in%20seen%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%E4%BD%BF%E7%94%A8%E7%94%A8%E6%88%B7%E6%8C%87%E5%AE%9A%E7%9A%84process_links%E5%A4%84%E7%90%86%E6%AF%8F%E4%B8%AA%E8%BF%9E%E6%8E%A5%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20links%20and%20rule.process_links%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20links%20%3D%20rule.process_links(links)%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%E5%B0%86%E9%93%BE%E6%8E%A5%E5%8A%A0%E5%85%A5seen%E9%9B%86%E5%90%88%EF%BC%8C%E4%B8%BA%E6%AF%8F%E4%B8%AA%E9%93%BE%E6%8E%A5%E7%94%9F%E6%88%90Request%E5%AF%B9%E8%B1%A1%EF%BC%8C%E5%B9%B6%E8%AE%BE%E7%BD%AE%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E4%B8%BA_repsonse_downloaded()%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20link%20in%20links%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20seen.add(link)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%E6%9E%84%E9%80%A0Request%E5%AF%B9%E8%B1%A1%EF%BC%8C%E5%B9%B6%E5%B0%86Rule%E8%A7%84%E5%88%99%E4%B8%AD%E5%AE%9A%E4%B9%89%E7%9A%84%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E4%BD%9C%E4%B8%BA%E8%BF%99%E4%B8%AARequest%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20r%20%3D%20Request(url%3Dlink.url%2C%20callback%3Dself._response_downloaded)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20r.meta.update(rule%3Dn%2C%20link_text%3Dlink.text)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%E5%AF%B9%E6%AF%8F%E4%B8%AARequest%E8%B0%83%E7%94%A8process_request()%E5%87%BD%E6%95%B0%E3%80%82%E8%AF%A5%E5%87%BD%E6%95%B0%E9%BB%98%E8%AE%A4%E4%B8%BAindentify%EF%BC%8C%E5%8D%B3%E4%B8%8D%E5%81%9A%E4%BB%BB%E4%BD%95%E5%A4%84%E7%90%86%EF%BC%8C%E7%9B%B4%E6%8E%A5%E8%BF%94%E5%9B%9E%E8%AF%A5Request.%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20yield%20rule.process_request(r)%0A%0A%20%20%20%20%23%E5%A4%84%E7%90%86%E9%80%9A%E8%BF%87rule%E6%8F%90%E5%8F%96%E5%87%BA%E7%9A%84%E8%BF%9E%E6%8E%A5%EF%BC%8C%E5%B9%B6%E8%BF%94%E5%9B%9Eitem%E4%BB%A5%E5%8F%8Arequest%0A%20%20%20%20def%20_response_downloaded(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20rule%20%3D%20self._rules%5Bresponse.meta%5B'rule'%5D%5D%0A%20%20%20%20%20%20%20%20return%20self._parse_response(response%2C%20rule.callback%2C%20rule.cb_kwargs%2C%20rule.follow)%0A%0A%20%20%20%20%23%E8%A7%A3%E6%9E%90response%E5%AF%B9%E8%B1%A1%EF%BC%8C%E4%BC%9A%E7%94%A8callback%E8%A7%A3%E6%9E%90%E5%A4%84%E7%90%86%E4%BB%96%EF%BC%8C%E5%B9%B6%E8%BF%94%E5%9B%9Erequest%E6%88%96Item%E5%AF%B9%E8%B1%A1%0A%20%20%20%20def%20_parse_response(self%2C%20response%2C%20callback%2C%20cb_kwargs%2C%20follow%3DTrue)%3A%0A%20%20%20%20%20%20%20%20%23%E9%A6%96%E5%85%88%E5%88%A4%E6%96%AD%E6%98%AF%E5%90%A6%E8%AE%BE%E7%BD%AE%E4%BA%86%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E3%80%82%EF%BC%88%E8%AF%A5%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E5%8F%AF%E8%83%BD%E6%98%AFrule%E4%B8%AD%E7%9A%84%E8%A7%A3%E6%9E%90%E5%87%BD%E6%95%B0%EF%BC%8C%E4%B9%9F%E5%8F%AF%E8%83%BD%E6%98%AF%20parse_start_url%E5%87%BD%E6%95%B0%EF%BC%89%0A%20%20%20%20%20%20%20%20%23%E5%A6%82%E6%9E%9C%E8%AE%BE%E7%BD%AE%E4%BA%86%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%EF%BC%88parse_start_url()%EF%BC%89%EF%BC%8C%E9%82%A3%E4%B9%88%E9%A6%96%E5%85%88%E7%94%A8parse_start_url()%E5%A4%84%E7%90%86response%E5%AF%B9%E8%B1%A1%EF%BC%8C%0A%20%20%20%20%20%20%20%20%23%E7%84%B6%E5%90%8E%E5%86%8D%E4%BA%A4%E7%BB%99process_results%E5%A4%84%E7%90%86%E3%80%82%E8%BF%94%E5%9B%9Ecb_res%E7%9A%84%E4%B8%80%E4%B8%AA%E5%88%97%E8%A1%A8%0A%20%20%20%20%20%20%20%20if%20callback%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%E5%A6%82%E6%9E%9C%E6%98%AFparse%E8%B0%83%E7%94%A8%E7%9A%84%EF%BC%8C%E5%88%99%E4%BC%9A%E8%A7%A3%E6%9E%90%E6%88%90Request%E5%AF%B9%E8%B1%A1%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%E5%A6%82%E6%9E%9C%E6%98%AFrule%20callback%EF%BC%8C%E5%88%99%E4%BC%9A%E8%A7%A3%E6%9E%90%E6%88%90Item%0A%20%20%20%20%20%20%20%20%20%20%20%20cb_res%20%3D%20callback(response%2C%20**cb_kwargs)%20or%20()%0A%20%20%20%20%20%20%20%20%20%20%20%20cb_res%20%3D%20self.process_results(response%2C%20cb_res)%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20requests_or_item%20in%20iterate_spider_output(cb_res)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20yield%20requests_or_item%0A%0A%20%20%20%20%20%20%20%20%23%E5%A6%82%E6%9E%9C%E9%9C%80%E8%A6%81%E8%B7%9F%E8%BF%9B%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BD%BF%E7%94%A8%E5%AE%9A%E4%B9%89%E7%9A%84Rule%E8%A7%84%E5%88%99%E6%8F%90%E5%8F%96%E5%B9%B6%E8%BF%94%E5%9B%9E%E8%BF%99%E4%BA%9BRequest%E5%AF%B9%E8%B1%A1%0A%20%20%20%20%20%20%20%20if%20follow%20and%20self._follow_links%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%E8%BF%94%E5%9B%9E%E6%AF%8F%E4%B8%AARequest%E5%AF%B9%E8%B1%A1%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20request_or_item%20in%20self._requests_to_follow(response)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20yield%20request_or_item%0A%0A%20%20%20%20def%20_compile_rules(self)%3A%0A%20%20%20%20%20%20%20%20def%20get_method(method)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20callable(method)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20method%0A%20%20%20%20%20%20%20%20%20%20%20%20elif%20isinstance(method%2C%20basestring)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20getattr(self%2C%20method%2C%20None)%0A%0A%20%20%20%20%20%20%20%20self._rules%20%3D%20%5Bcopy.copy(r)%20for%20r%20in%20self.rules%5D%0A%20%20%20%20%20%20%20%20for%20rule%20in%20self._rules%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20rule.callback%20%3D%20get_method(rule.callback)%0A%20%20%20%20%20%20%20%20%20%20%20%20rule.process_links%20%3D%20get_method(rule.process_links)%0A%20%20%20%20%20%20%20%20%20%20%20%20rule.process_request%20%3D%20get_method(rule.process_request)%0A%0A%20%20%20%20def%20set_crawler(self%2C%20crawler)%3A%0A%20%20%20%20%20%20%20%20super(CrawlSpider%2C%20self).set_crawler(crawler)%0A%20%20%20%20%20%20%20%20self._follow_links%20%3D%20crawler.settings.getbool('CRAWLSPIDER_FOLLOW_LINKS'%2C%20True)%0A%60%60%60%0A%0A%23%23%23%20%E5%88%9B%E5%BB%BA%E7%88%AC%E8%99%AB%E6%96%87%E4%BB%B6%0A%0A%E9%80%9A%E8%BF%87%E4%B8%8B%E9%9D%A2%E7%9A%84%E5%91%BD%E4%BB%A4%E5%8F%AF%E4%BB%A5%E5%BF%AB%E9%80%9F%E5%88%9B%E5%BB%BA%20CrawlSpider%E6%A8%A1%E6%9D%BF%20%E7%9A%84%E4%BB%A3%E7%A0%81%EF%BC%9A%0A%60%60%60%0Ascrapy%20genspider%20-t%20crawl%20%E7%88%AC%E8%99%AB%E6%96%87%E4%BB%B6%20%E5%9F%9F%E5%90%8D%0A%60%60%60%0A%0A**CrawlSpider**%E7%BB%A7%E6%89%BF%E4%BA%8E**Spider**%E7%B1%BB%EF%BC%8C%E9%99%A4%E4%BA%86%E7%BB%A7%E6%89%BF%E8%BF%87%E6%9D%A5%E7%9A%84%E5%B1%9E%E6%80%A7%E5%A4%96%EF%BC%88name%E3%80%81allow_domains%EF%BC%89%EF%BC%8C%E8%BF%98%E6%8F%90%E4%BE%9B%E4%BA%86%E6%96%B0%E7%9A%84%E5%B1%9E%E6%80%A7%E5%92%8C%E6%96%B9%E6%B3%95%3A%0A%60%60%60%0Aclass%20XcfcrawlspiderSpider(CrawlSpider)%3A%0A%20%20%20%20%23%E7%88%AC%E8%99%AB%E5%90%8D%E7%A7%B0%0A%20%20%20%20name%20%3D%20'xcfCrawlSpider'%0A%20%20%20%20%23%E8%AE%BE%E7%BD%AE%E5%85%81%E8%AE%B8%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F%0A%20%20%20%20allowed_domains%20%3D%20%5B'xiachufang.com'%5D%0A%20%20%20%20%23%E8%AE%BE%E7%BD%AE%E8%B5%B7%E5%A7%8B%E7%9A%84url%0A%20%20%20%20start_urls%20%3D%20%5B'http%3A%2F%2Fwww.xiachufang.com%2Fcategory%2F'%5D%0A%20%20%20%20rules%20%3D%20(%0A%20%20%20%20%20%20%20%20Rule(%0A%20%20%20%20%20%20%20%20%20%20%20%20LinkExtractor(allow%3Dr'.*%3F%2Fcategory%2F%5Cd%2B%2F')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20callback%3D'parse_item'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20follow%3DTrue%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20process_links%3D'check_category_url'%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20)%0A%60%60%60%0A%0A%23%23%23%20**rules**%0A%0A**CrawlSpider**%E4%BD%BF%E7%94%A8**rules**%E5%B1%9E%E6%80%A7%E6%9D%A5%E5%86%B3%E5%AE%9A%E7%88%AC%E8%99%AB%E7%9A%84%E7%88%AC%E5%8F%96%E8%A7%84%E5%88%99%EF%BC%8C%E5%B9%B6%E5%B0%86%E5%8C%B9%E9%85%8D%E5%90%8E%E7%9A%84url%E8%AF%B7%E6%B1%82%E6%8F%90%E4%BA%A4%E7%BB%99%E5%BC%95%E6%93%8E%2C%E5%AE%8C%E6%88%90%E5%90%8E%E7%BB%AD%E7%9A%84%E7%88%AC%E5%8F%96%E5%B7%A5%E4%BD%9C%E3%80%82%0A%0A%E5%9C%A8**rules**%E4%B8%AD%E5%8C%85%E5%90%AB%E4%B8%80%E4%B8%AA%E6%88%96%E5%A4%9A%E4%B8%AA**Rule**%E5%AF%B9%E8%B1%A1%EF%BC%8C%E6%AF%8F%E4%B8%AARule%E5%AF%B9%E7%88%AC%E5%8F%96%E7%BD%91%E7%AB%99%E7%9A%84%E5%8A%A8%E4%BD%9C%E5%AE%9A%E4%B9%89%E4%BA%86%E6%9F%90%E7%A7%8D%E7%89%B9%E5%AE%9A%E6%93%8D%E4%BD%9C%EF%BC%8C%E6%AF%94%E5%A6%82%E6%8F%90%E5%8F%96%E5%BD%93%E5%89%8D%E7%9B%B8%E5%BA%94%E5%86%85%E5%AE%B9%E9%87%8C%E7%9A%84%E7%89%B9%E5%AE%9A%E9%93%BE%E6%8E%A5%EF%BC%8C%E6%98%AF%E5%90%A6%E5%AF%B9%E6%8F%90%E5%8F%96%E7%9A%84%E9%93%BE%E6%8E%A5%E8%B7%9F%E8%BF%9B%E7%88%AC%E5%8F%96%EF%BC%8C%E5%AF%B9%E6%8F%90%E4%BA%A4%E7%9A%84%E8%AF%B7%E6%B1%82%E8%AE%BE%E7%BD%AE%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E7%AD%89%E3%80%82%0A%0A%E6%B3%A8%E6%84%8F%3A%0A%0A**%E5%A6%82%E6%9E%9C%E5%A4%9A%E4%B8%AArule%E5%8C%B9%E9%85%8D%E4%BA%86%E7%9B%B8%E5%90%8C%E7%9A%84%E9%93%BE%E6%8E%A5%EF%BC%8C%E5%88%99%E6%A0%B9%E6%8D%AE%E8%A7%84%E5%88%99%E5%9C%A8%E6%9C%AC%E9%9B%86%E5%90%88%E4%B8%AD%E8%A2%AB%E5%AE%9A%E4%B9%89%E7%9A%84%E9%A1%BA%E5%BA%8F%EF%BC%8C%E7%AC%AC%E4%B8%80%E4%B8%AA%E4%BC%9A%E8%A2%AB%E4%BD%BF%E7%94%A8**%E3%80%82%0A%0A%60%60%60%0Aclass%20scrapy.spiders.Rule(%0A%20%20%20%20%20%20%20%20link_extractor%2C%0A%20%20%20%20%20%20%20%20callback%20%3D%20None%2C%0A%20%20%20%20%20%20%20%20cb_kwargs%20%3D%20None%2C%0A%20%20%20%20%20%20%20%20follow%20%3D%20None%2C%0A%20%20%20%20%20%20%20%20process_links%20%3D%20None%2C%0A%20%20%20%20%20%20%20%20process_request%20%3D%20None%0A)%0A%60%60%60%0A-%20**link_extractor**%EF%BC%9A%E6%98%AF%E4%B8%80%E4%B8%AALink%20Extractor%E5%AF%B9%E8%B1%A1%EF%BC%8C%E7%94%A8%E4%BA%8E%E5%AE%9A%E4%B9%89%E9%9C%80%E8%A6%81%E6%8F%90%E5%8F%96%E7%9A%84%E9%93%BE%E6%8E%A5%E3%80%82%0A%0A-%20**callback**%EF%BC%9A%20%E4%BB%8Elink_extractor%E4%B8%AD%E6%AF%8F%E8%8E%B7%E5%8F%96%E5%88%B0%E9%93%BE%E6%8E%A5%E5%BE%97%E5%88%B0Responses%E6%97%B6%EF%BC%8C%E4%BC%9A%E8%B0%83%E7%94%A8%E5%8F%82%E6%95%B0%E6%89%80%E6%8C%87%E5%AE%9A%E7%9A%84%E5%80%BC%E4%BD%9C%E4%B8%BA%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%EF%BC%8C%E8%AF%A5%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E6%8E%A5%E6%94%B6%E4%B8%80%E4%B8%AAresponse%E4%BD%9C%E4%B8%BA%E5%85%B6%E4%B8%80%E4%B8%AA%E5%8F%82%E6%95%B0%E3%80%82%0A%0A-%20**follow**%EF%BC%9A%E6%98%AF%E4%B8%80%E4%B8%AA%E5%B8%83%E5%B0%94(boolean)%E5%80%BC%EF%BC%8C%E6%8C%87%E5%AE%9A%E4%BA%86%E6%A0%B9%E6%8D%AE%E8%AF%A5%E8%A7%84%E5%88%99%E4%BB%8Eresponse%E6%8F%90%E5%8F%96%E7%9A%84%E9%93%BE%E6%8E%A5%E6%98%AF%E5%90%A6%E9%9C%80%E8%A6%81%E8%B7%9F%E8%BF%9B%E3%80%82**%E5%A6%82%E6%9E%9Ccallback%E4%B8%BANone%EF%BC%8Cfollow%20%E9%BB%98%E8%AE%A4%E8%AE%BE%E7%BD%AE%E4%B8%BATrue%20%EF%BC%8C%E5%90%A6%E5%88%99%E9%BB%98%E8%AE%A4%E4%B8%BAFalse%E3%80%82**%0A%0A-%20**process_links**%EF%BC%9A%E6%8C%87%E5%AE%9Aspider%E4%B8%AD%E5%93%AA%E4%B8%AA%E7%9A%84%E5%87%BD%E6%95%B0%E5%B0%86%E4%BC%9A%E8%A2%AB%E8%B0%83%E7%94%A8%EF%BC%8C%E4%BB%8Elink_extractor%E4%B8%AD%E8%8E%B7%E5%8F%96%E5%88%B0%E9%93%BE%E6%8E%A5%E5%88%97%E8%A1%A8%E6%97%B6%E5%B0%86%E4%BC%9A%E8%B0%83%E7%94%A8%E8%AF%A5%E5%87%BD%E6%95%B0%E3%80%82%E8%AF%A5%E6%96%B9%E6%B3%95%E4%B8%BB%E8%A6%81%E7%94%A8%E6%9D%A5%E8%BF%87%E6%BB%A4%E3%80%82%0A%0A-%20**process_request**%EF%BC%9A%E6%8C%87%E5%AE%9A%E5%A4%84%E7%90%86%E5%87%BD%E6%95%B0%EF%BC%8C%E6%A0%B9%E6%8D%AE%E8%AF%A5Rule%E6%8F%90%E5%8F%96%E5%88%B0%E7%9A%84%E6%AF%8F%E4%B8%AARequest%E6%97%B6%EF%BC%8C%E8%AF%A5%E5%87%BD%E6%95%B0%E5%B0%86%E4%BC%9A%E8%A2%AB%E8%B0%83%E7%94%A8%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%AF%B9Request%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86%EF%BC%8C%E8%AF%A5%E5%87%BD%E6%95%B0%E5%BF%85%E9%A1%BB%E8%BF%94%E5%9B%9ERequest%E6%88%96%E8%80%85None%0A%0A%E6%B3%A8%E6%84%8F%EF%BC%9A**%E5%BD%93%E7%BC%96%E5%86%99%E7%88%AC%E8%99%AB%E8%A7%84%E5%88%99%E6%97%B6%EF%BC%8C%E9%81%BF%E5%85%8D%E4%BD%BF%E7%94%A8parse%E4%BD%9C%E4%B8%BA%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E3%80%82%E7%94%B1%E4%BA%8ECrawlSpider%E4%BD%BF%E7%94%A8parse%E6%96%B9%E6%B3%95%E6%9D%A5%E5%AE%9E%E7%8E%B0%E5%85%B6%E9%80%BB%E8%BE%91%EF%BC%8C%E5%A6%82%E6%9E%9C%E8%A6%86%E7%9B%96%E4%BA%86%20parse%E6%96%B9%E6%B3%95%EF%BC%8Ccrawl%20spider%E5%B0%86%E4%BC%9A%E8%BF%90%E8%A1%8C%E5%A4%B1%E8%B4%A5**%E3%80%82%0A%0A%0A%23%23%23%23%20**LinkExtractors**%0A%60%60%60%0Aclass%20scrapy.linkextractors.LinkExtractor%0A%60%60%60%0A%0ALinkExtractors%20%E7%9A%84%E7%9B%AE%E7%9A%84%E5%BE%88%E7%AE%80%E5%8D%95%3A%20**%E6%8F%90%E5%8F%96%E9%93%BE%E6%8E%A5**%EF%BD%A1%0A%0A%E6%AF%8F%E4%B8%AALinkExtractor%E6%9C%89%E5%94%AF%E4%B8%80%E7%9A%84%E5%85%AC%E5%85%B1%E6%96%B9%E6%B3%95%E6%98%AF%20**extract_links()**%EF%BC%8C%E5%AE%83%E6%8E%A5%E6%94%B6%E4%B8%80%E4%B8%AA%20Response%20%E5%AF%B9%E8%B1%A1%EF%BC%8C%E5%B9%B6%E8%BF%94%E5%9B%9E%E4%B8%80%E4%B8%AA%20**scrapy.link.Link**%20%E5%AF%B9%E8%B1%A1%E3%80%82%0A%0ALinkExtractors%E8%A6%81%E5%AE%9E%E4%BE%8B%E5%8C%96%E4%B8%80%E6%AC%A1%EF%BC%8C%E5%B9%B6%E4%B8%94%20extract_links%20%E6%96%B9%E6%B3%95%E4%BC%9A%E6%A0%B9%E6%8D%AE%E4%B8%8D%E5%90%8C%E7%9A%84%20response%20%E8%B0%83%E7%94%A8%E5%A4%9A%E6%AC%A1%E6%8F%90%E5%8F%96%E9%93%BE%E6%8E%A5%EF%BD%A1%0A%0A%60%60%60%0Aclass%20scrapy.linkextractors.LinkExtractor(%0A%20%20%20%20allow%20%3D%20()%2C%0A%20%20%20%20deny%20%3D%20()%2C%0A%20%20%20%20allow_domains%20%3D%20()%2C%0A%20%20%20%20deny_domains%20%3D%20()%2C%0A%20%20%20%20deny_extensions%20%3D%20None%2C%0A%20%20%20%20restrict_xpaths%20%3D%20()%2C%0A%20%20%20%20tags%20%3D%20('a'%2C'area')%2C%0A%20%20%20%20attrs%20%3D%20('href')%2C%0A%20%20%20%20canonicalize%20%3D%20True%2C%0A%20%20%20%20unique%20%3D%20True%2C%0A%20%20%20%20process_value%20%3D%20None%0A)%0A%60%60%60%0A%E4%B8%BB%E8%A6%81%E5%8F%82%E6%95%B0%EF%BC%9A%0A%0A-%20allow%EF%BC%9A%E6%BB%A1%E8%B6%B3%E6%8B%AC%E5%8F%B7%E4%B8%AD%E2%80%9C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E2%80%9D%E7%9A%84URL%E4%BC%9A%E8%A2%AB%E6%8F%90%E5%8F%96%EF%BC%8C%E5%A6%82%E6%9E%9C%E4%B8%BA%E7%A9%BA%EF%BC%8C%E5%88%99%E5%85%A8%E9%83%A8%E5%8C%B9%E9%85%8D%E3%80%82%0A%0A-%20deny%EF%BC%9A%E6%BB%A1%E8%B6%B3%E6%8B%AC%E5%8F%B7%E4%B8%AD%E2%80%9C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E2%80%9D%E7%9A%84URL%E4%B8%80%E5%AE%9A%E4%B8%8D%E6%8F%90%E5%8F%96%EF%BC%88%E4%BC%98%E5%85%88%E7%BA%A7%E9%AB%98%E4%BA%8Eallow%EF%BC%89%E3%80%82%0A%0A-%20allow_domains%EF%BC%9A%E4%BC%9A%E6%8F%90%E5%8F%96%E7%9A%84%E9%93%BE%E6%8E%A5%E7%9A%84domains%E3%80%82%0A%0A-%20deny_domains%EF%BC%9A%E4%B8%80%E5%AE%9A%E4%B8%8D%E4%BC%9A%E8%A2%AB%E6%8F%90%E5%8F%96%E9%93%BE%E6%8E%A5%E7%9A%84domains%E3%80%82%0A%0A-%20restrict_xpaths%EF%BC%9A%E4%BD%BF%E7%94%A8xpath%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%8C%E5%92%8Callow%E5%85%B1%E5%90%8C%E4%BD%9C%E7%94%A8%E8%BF%87%E6%BB%A4%E9%93%BE%E6%8E%A5%E3%80%82%0A%0A%0A%0A%23%23%23%20**%E7%88%AC%E5%8F%96%E8%A7%84%E5%88%99(Crawling%20rules)**%0A%0A%23%23%23%20**%E4%B8%8B%E5%8E%A8%E6%88%BF%E6%A1%88%E4%BE%8B**%0A%0A1.%20%E5%8F%AF%E4%BB%A5%E5%85%88%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%0A2.%20%E8%BF%9B%E5%85%A5%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%EF%BC%8C%E5%88%9B%E5%BB%BA%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%0A%0A%E4%B8%8A%E9%9D%A2%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E7%9A%84%E7%9A%84%E6%AD%A5%E9%AA%A4%E8%BF%99%E9%87%8C%E4%B8%8D%E5%9C%A8%E8%AE%B2%E8%A7%A3%EF%BC%8C%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%88%9B%E5%BB%BA%E5%AE%8C%E6%AF%95%E5%90%8E%E6%88%91%E4%BB%AC%E5%88%9B%E5%BB%BA%E6%99%BA%E8%81%94%E7%9A%84%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%0A%0A1.%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AEscrapy%20startproject%20xiachufang(%E9%A1%B9%E7%9B%AE%E5%90%8D%E7%A7%B0)%0A2.%E8%BF%9B%E5%85%A5spiders%E7%9B%AE%E5%BD%95%E5%88%9B%E5%BB%BAxiachufang%E7%88%AC%E8%99%AB%E6%96%87%E4%BB%B6%0A%20%20scrapy%20gen%20spider%20-t%20crawl%20xcfcrawlspider%20xiachufang.com%0A3.%E6%89%A7%E8%A1%8C%E5%AE%8C%E6%88%90%E5%90%8E%E4%BD%BF%E7%94%A8scrapy%20list%E6%9F%A5%E7%9C%8B%E5%BD%93%E5%89%8D%E5%AD%98%E5%9C%A8%E7%9A%84spider%E7%88%AC%E8%99%AB%E6%96%87%E4%BB%B6%0A%0A**%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E6%A0%B9%E6%8D%AE%E8%A6%81%E7%88%AC%E5%8F%96%E7%9A%84%E7%BD%91%E9%A1%B5%E7%A1%AE%E5%AE%9A%E9%9C%80%E8%A6%81%E4%BF%9D%E5%AD%98%E7%9A%84%E5%AD%97%E6%AE%B5**%0A%0A**Item.py%3A%E5%AE%9A%E4%B9%89%E9%9C%80%E8%A6%81%E7%88%AC%E5%8F%96%E7%9A%84%E5%AD%97%E6%AE%B5**%0A%60%60%60%0Aclass%20XiachufangItem(scrapy.Item)%3A%0A%20%20%20%20%23%E5%9B%BE%E7%89%87%E9%93%BE%E6%8E%A5%0A%20%20%20%20coverImage%20%3D%20scrapy.Field()%0A%20%20%20%20%23%E5%90%8D%E7%A7%B0%0A%20%20%20%20title%20%3D%20scrapy.Field()%0A%20%20%20%20%23%E8%AF%84%E5%88%86%0A%20%20%20%20score%20%3D%20scrapy.Field()%0A%20%20%20%20%23%E5%A4%9A%E5%B0%91%E4%BA%BA%E5%81%9A%E8%BF%87%0A%20%20%20%20doitnum%20%3D%20scrapy.Field()%0A%20%20%20%20%23%E5%8F%91%E5%B8%83%E4%BA%BA%0A%20%20%20%20author%20%3D%20scrapy.Field()%0A%20%20%20%20%23%E7%94%A8%E6%96%99%0A%20%20%20%20used%20%3D%20scrapy.Field()%0A%20%20%20%20%23%E5%81%9A%E6%B3%95%0A%20%20%20%20methodway%20%3D%20scrapy.Field()%0A%0A%20%20%20%20def%20insert_data_to_db(self%2CdataDict)%3A%0A%20%20%20%20%20%20%20%20sql%20%3D%20%22%22%22%0A%20%20%20%20%20%20%20%20INSERT%20INTO%20caipu%20(%25s)%0A%20%20%20%20%20%20%20%20VALUES%20(%25s)%0A%20%20%20%20%20%20%20%20%22%22%22%20%25%20('%2C'.join(dataDict.keys())%2C'%2C'.join(%5B'%25s'%5D*len(dataDict)))%0A%0A%20%20%20%20%20%20%20%20data%20%3D%20list(dataDict.values())%0A%0A%20%20%20%20%20%20%20%20return%20sql%2Cdata%0A%60%60%60%0A%0A**%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E7%BC%96%E5%86%99%E7%88%AC%E8%99%AB%E7%B1%BB**%0A%0A**LinkExtractor%E5%AE%9E%E4%BE%8B%E5%AF%B9%E8%B1%A1**%0A%0A%23%23%23%23%20%E6%A0%B9%E6%8D%AE%E9%9C%80%E8%A6%81%E6%8F%90%E5%8F%96%E7%9A%84%E9%A1%B5%E9%9D%A2%E7%9A%84url%E6%9D%A5%E8%AE%BE%E7%BD%AE%E9%9C%80%E8%A6%81%E6%8F%90%E5%8F%96%E7%9A%84%E8%A7%84%E5%88%99%0A%0A-%20LinkExtractor%E6%96%B9%E6%B3%95%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E7%9A%84%E5%8F%82%E6%95%B0%0A-%20allow%20%3A%20LinkExtractor%E5%AF%B9%E8%B1%A1%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E5%8F%82%E6%95%B0%E4%B9%8B%E4%B8%80%EF%BC%8C%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%8C%E5%BF%85%E9%A1%BB%E8%A6%81%E5%8C%B9%E9%85%8D%E8%BF%99%E4%B8%AA%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F(%E6%88%96%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%88%97%E8%A1%A8)%E7%9A%84URL%E6%89%8D%E4%BC%9A%E8%A2%AB%E6%8F%90%E5%8F%96%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%E7%BB%99%E5%87%BA(%E6%88%96%E4%B8%BA%E7%A9%BA)%2C%20%E5%AE%83%E4%BC%9A%E5%8C%B9%E9%85%8D%E6%89%80%E6%9C%89%E7%9A%84%E9%93%BE%E6%8E%A5%EF%BD%A1%0A-%20deny%20%3A%20%E7%94%A8%E6%B3%95%E5%90%8Callow%EF%BC%8C%E5%8F%AA%E4%B8%8D%E8%BF%87%E4%B8%8E%E8%BF%99%E4%B8%AA%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D%E7%9A%84URL%E4%B8%8D%E4%BC%9A%E8%A2%AB%E6%8F%90%E5%8F%96)%EF%BD%A1%E5%AE%83%E7%9A%84%E4%BC%98%E5%85%88%E7%BA%A7%E9%AB%98%E4%BA%8E%20-%20allow%20%E7%9A%84%E5%8F%82%E6%95%B0%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%B2%A1%E6%9C%89%E7%BB%99%E5%87%BA(%E6%88%96None)%2C%20%E5%B0%86%E4%B8%8D%E6%8E%92%E9%99%A4%E4%BB%BB%E4%BD%95%E9%93%BE%E6%8E%A5%EF%BD%A1%0A%0A-%20allow_domains%3A%E5%8C%85%E5%90%AB%E4%BA%86spider%E5%85%81%E8%AE%B8%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F%E5%90%8D(domain)%E5%88%97%E8%A1%A8(list)%0A-%20deny_domains%3D()%3A%E5%8C%85%E5%90%AB%E4%BA%86spider%E4%B8%8D%E5%85%81%E8%AE%B8%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F%E5%90%8D(domain)%E5%88%97%E8%A1%A8(list)%20%20%0A%0A**spider%E7%88%AC%E8%99%AB%E6%96%87%E4%BB%B6%E4%BB%A3%E7%A0%81**%0A%0A%60%60%60%0A%23%20-*-%20coding%3A%20utf-8%20-*-%0Aimport%20scrapy%0Afrom%20scrapy.linkextractors%20import%20LinkExtractor%0Afrom%20scrapy.spiders%20import%20CrawlSpider%2C%20Rule%0A%23%E9%80%9A%E7%94%A8%E7%88%AC%E8%99%AB%E6%8F%90%E5%8F%96%E5%88%B0%E7%9A%84%E8%BF%9E%E6%8E%A5%E4%BC%9A%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AALink%E5%AF%B9%E8%B1%A1%0Afrom%20scrapy.link%20import%20Link%0Afrom%20xiachufang.items%20import%20XiachufangItem%0A%0A%23%E5%88%9B%E5%BB%BA%E9%80%9A%E7%94%A8%E7%88%AC%E8%99%AB%E7%9A%84%E5%91%BD%E4%BB%A4%EF%BC%9Ascrapy%20genspider%20-t%20crawl%20%E7%88%AC%E8%99%AB%E5%90%8D%E7%A7%B0%E3%80%80%E5%9F%9F%0A%0Aclass%20XcfcrawlspiderSpider(CrawlSpider)%3A%0A%20%20%20%20%23%E7%88%AC%E8%99%AB%E5%90%8D%E7%A7%B0%0A%20%20%20%20name%20%3D%20'xcfCrawlSpider'%0A%20%20%20%20%23%E8%AE%BE%E7%BD%AE%E5%85%81%E8%AE%B8%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F%0A%20%20%20%20allowed_domains%20%3D%20%5B'xiachufang.com'%5D%0A%20%20%20%20%23%E8%AE%BE%E7%BD%AE%E8%B5%B7%E5%A7%8B%E7%9A%84url%0A%20%20%20%20start_urls%20%3D%20%5B'http%3A%2F%2Fwww.xiachufang.com%2Fcategory%2F'%5D%0A%0A%20%20%20%20%23%20rules%3A%E6%98%AF%E4%B8%80%E4%B8%AA%E5%85%83%E7%BB%84%EF%BC%88%E5%88%97%E8%A1%A8%EF%BC%89%2C%E9%87%8C%E9%9D%A2%E5%AD%98%E6%94%BE%E7%9A%84%E6%98%AF%E8%A7%84%E5%88%99Rule%E8%A7%84%E5%88%99%E5%AF%B9%E8%B1%A1%0A%20%20%20%20%23%20%E5%8F%AF%E4%BB%A5%E6%9C%89%E5%A4%9A%E4%B8%AA%E8%A7%84%E5%88%99%0A%0A%20%20%20%20%23Rule%3A%0A%20%20%20%20%23LinkExtractor%3A%E8%AE%BE%E7%BD%AE%E6%8F%90%E5%8F%96%E8%A7%84%E5%88%99%0A%20%20%20%20%23callback%3A%E8%AE%BE%E7%BD%AE%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%EF%BC%88%E8%8E%B7%E5%8F%96%E5%93%8D%E5%BA%94%2C%E8%A7%A3%E6%9E%90%E6%95%B0%E6%8D%AE%EF%BC%89%0A%20%20%20%20%23follow%3A%E8%AE%BE%E7%BD%AE%E6%98%AF%E5%90%A6%E9%9C%80%E8%A6%81%E8%B7%9F%E8%BF%9B%0A%0A%20%20%20%20rules%20%3D%20(%0A%20%20%20%20%20%20%20%20%23%E5%88%86%E7%B1%BB%E5%88%97%E8%A1%A8%E5%9C%B0%E5%9D%80%0A%20%20%20%20%20%20%20%20%23%20http%3A%2F%2Fwww.xiachufang.com%2Fcategory%2F40073%2F%0A%20%20%20%20%20%20%20%20Rule(%0A%20%20%20%20%20%20%20%20%20%20%20%20LinkExtractor(allow%3Dr'.*%3F%2Fcategory%2F%5Cd%2B%2F')%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20callback%3D'parse_item'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20follow%3DTrue%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20process_links%3D'check_category_url'%0A%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20%23%20%E8%8F%9C%E5%8D%95%E8%AF%A6%E6%83%85%E5%9C%B0%E5%9D%80%2C%0A%20%20%20%20%20%20%20%20%23%20http%3A%2F%2Fwww.xiachufang.com%2Frecipe%2F1055105%2F%0A%20%20%20%20%20%20%20%20%23%20http%3A%2F%2Fwww.xiachufang.com%2Frecipe%2F12137%2F%0A%20%20%20%20%20%20%20%20%23%20http%3A%2F%2Fwww.xiachufang.com%2Frecipe%2F100147684%2F%0A%20%20%20%20%20%20%20%20Rule(%0A%20%20%20%20%20%20%20%20%20%20%20%20LinkExtractor(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20allow%3Dr'.*%3F%2Frecipe%2F%5Cd%2B%2F'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20callback%3D'parse_caipu_detail'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20follow%3DFalse%2C%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20)%0A%0A%20%20%20%20%23%20def%20parse(self)%3A%20%E4%B8%80%E5%AE%9A%E4%B8%8D%E8%83%BD%E5%87%BA%E7%8E%B0%E8%BF%99%E4%B8%AA%E6%96%B9%E6%B3%95%2C%E5%9B%A0%E4%B8%BAcrawlSpider%E4%BD%BF%E7%94%A8%E4%BA%86%E8%BF%99%E4%B8%AA%E6%96%B9%E6%B3%95%0A%0A%20%20%20%20def%20parse_item(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20print('%E5%88%86%E7%B1%BB%E8%8E%B7%E5%8F%96%E6%88%90%E5%8A%9F')%0A%20%20%20%20%20%20%20%20print(response.status%2Cresponse.url)%0A%0A%20%20%20%20def%20check_category_url(self%2Clinks)%3A%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%E5%8F%AF%E4%BB%A5%E5%9C%A8%E6%AD%A4%E6%96%B9%E6%B3%95%E5%81%9A%E5%AF%B9%E8%A7%84%E5%88%99%E6%8F%90%E5%8F%96%E7%9A%84url%E6%9E%84%E5%BB%BA%E6%88%90%E7%9A%84%E7%9A%84link%E5%AF%B9%E8%B1%A1%E5%81%9A%E8%BF%87%E6%BB%A4%E5%A4%84%E7%90%86%0A%20%20%20%20%20%20%20%20%3Aparam%20links%3A%0A%20%20%20%20%20%20%20%20%3Areturn%3A%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20print('%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D'%2Clinks%2C'%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D%3D')%0A%20%20%20%20%20%20%20%20return%20links%0A%0A%20%20%20%20def%20parse_caipu_detail(self%2Cresponse)%3A%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%E8%8F%9C%E8%B0%B1%E8%AF%A6%E6%83%85%E8%AF%B7%E6%B1%82%E6%88%90%E5%8A%9F%E5%90%8E%E7%9A%84%E7%BB%93%E6%9E%9C%E5%A4%84%E7%90%86%2C%E4%BB%8E%E5%93%8D%E5%BA%94%E7%BB%93%E6%9E%9C%E4%B8%AD%E6%8F%90%E5%8F%96%E7%9B%AE%E6%A0%87%E6%95%B0%E6%8D%AE%0A%20%20%20%20%20%20%20%20%3Aparam%20response%3A%0A%20%20%20%20%20%20%20%20%3Areturn%3A%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20print('%E8%AF%A6%E6%83%85%E8%8E%B7%E5%8F%96%E6%88%90%E5%8A%9F')%0A%20%20%20%20%20%20%20%20print(response.status%2Cresponse.url)%0A%20%20%20%20%20%20%20%20%23%20%E5%8F%96%E5%87%BAitem%0A%20%20%20%20%20%20%20%20item%20%3D%20XiachufangItem()%0A%20%20%20%20%20%20%20%20%23%20%E5%9B%BE%E7%89%87%E9%93%BE%E6%8E%A5%0A%20%20%20%20%20%20%20%20item%5B'coverImage'%5D%20%3D%20response.xpath('%2F%2Fdiv%5B%40class%3D%22cover%20image%20expandable%20block-negative-margin%22%5D%2Fimg%2F%40src').extract_first('')%0A%20%20%20%20%20%20%20%20%23%20%E5%90%8D%E7%A7%B0%0A%20%20%20%20%20%20%20%20item%5B'title'%5D%20%3D%20''.join(response.xpath('%2F%2Fh1%5B%40class%3D%22page-title%22%5D%2Ftext()').extract()).replace('%20'%2C'').replace('%5Cn'%2C'')%0A%20%20%20%20%20%20%20%20%23%20%E8%AF%84%E5%88%86%0A%20%20%20%20%20%20%20%20item%5B'score'%5D%20%3D%20response.xpath('%2F%2Fdiv%5B%40class%3D%22score%20float-left%22%5D%2Fspan%5B%40class%3D%22number%22%5D%2Ftext()').extract_first('')%0A%20%20%20%20%20%20%20%20%23%20%E5%A4%9A%E5%B0%91%E4%BA%BA%E5%81%9A%E8%BF%87%0A%20%20%20%20%20%20%20%20item%5B'doitnum'%5D%20%3D%20response.xpath('%2F%2Fdiv%5B%40class%3D%22cooked%20float-left%22%5D%2Fspan%5B%40class%3D%22number%22%5D%2Ftext()').extract_first('')%0A%20%20%20%20%20%20%20%20%23%20%E5%8F%91%E5%B8%83%E4%BA%BA%0A%20%20%20%20%20%20%20%20item%5B'author'%5D%20%3D%20response.xpath('%2F%2Fdiv%5B%40class%3D%22author%22%5D%2Fa%5B1%5D%2Fspan%2Ftext()').extract_first('')%0A%20%20%20%20%20%20%20%20%23%20%E8%8E%B7%E5%8F%96%E7%94%A8%E6%96%99%E7%9A%84%E5%88%97%E8%A1%A8%0A%20%20%20%20%20%20%20%20%23%20%E5%AF%B9%E5%90%93%EF%BC%9A8%E5%8F%AA%3B%E5%AF%B9%E5%90%93%EF%BC%9A8%E5%8F%AA%3B%E5%AF%B9%E5%90%93%EF%BC%9A8%E5%8F%AA%3B%E5%AF%B9%E5%90%93%EF%BC%9A8%E5%8F%AA%3B%E5%AF%B9%E5%90%93%EF%BC%9A8%E5%8F%AA%0A%20%20%20%20%20%20%20%20tr_list%20%3D%20response.css('div.ings%20tr')%0A%20%20%20%20%20%20%20%20used_list%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20tr%20in%20tr_list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20name%20%3D%20''.join(tr.css('td.name%20%3A%3Atext').extract()).replace('%5Cn'%2C%20'').replace('%20'%2C%20'')%0A%20%20%20%20%20%20%20%20%20%20%20%20value%20%3D%20''.join(tr.css('td.unit%20%3A%3Atext').extract()).replace('%5Cn'%2C%20'').replace('%20'%2C%20'')%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20len(value)%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20value%20%3D%20'%E8%8B%A5%E5%B9%B2'%0A%20%20%20%20%20%20%20%20%20%20%20%20used_list.append(name%20%2B%20'%3A'%20%2B%20value)%0A%20%20%20%20%20%20%20%20item%5B'used'%5D%20%3D%20'%3B'.join(used_list)%0A%20%20%20%20%20%20%20%20%23%20%E8%8E%B7%E5%8F%96%E5%81%9A%E6%B3%95%0A%20%20%20%20%20%20%20%20item%5B'methodway'%5D%20%3D%20'-%3E'.join(response.css('div.steps%20p.text%20%3A%3Atext').extract())%0A%20%20%20%20%20%20%20%20print(item)%0A%20%20%20%20%20%20%20%20%23%20yield%20item%0A%0A%60%60%60%0A%0A%0A**%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E6%95%B0%E6%8D%AE%E4%BF%9D%E5%AD%98**%0A%0A**pipelines%E7%AE%A1%E9%81%93%E6%96%87%E4%BB%B6**%0A%60%60%60%0Aimport%20pymysql%0A%0Aclass%20XiachufangPipeline(object)%3A%0A%0A%20%20%20%20def%20__init__(self%2Chost%2Cport%2Cuser%2Cpwd%2Cdb%2Ccharset)%3A%0A%0A%20%20%20%20%20%20%20%20self.client%20%3D%20pymysql.Connect(host%2Cuser%2Cpwd%2Cdb%2Cport%2Ccharset%3Dcharset)%0A%20%20%20%20%20%20%20%20self.cursor%20%3D%20self.client.cursor()%0A%0A%20%20%20%20%40classmethod%0A%20%20%20%20def%20from_crawler(cls%2Ccrawler)%3A%0A%20%20%20%20%20%20%20%20host%20%3D%20crawler.settings%5B'MYSQL_HOST'%5D%0A%20%20%20%20%20%20%20%20port%20%3D%20crawler.settings%5B'MYSQL_PORT'%5D%0A%20%20%20%20%20%20%20%20user%20%3D%20crawler.settings%5B'MYSQL_USER'%5D%0A%20%20%20%20%20%20%20%20pwd%20%3D%20crawler.settings%5B'MYSQL_PWD'%5D%0A%20%20%20%20%20%20%20%20db%20%3D%20crawler.settings%5B'MYSQL_DB'%5D%0A%20%20%20%20%20%20%20%20charset%20%3D%20crawler.settings%5B'CHARSET'%5D%0A%0A%20%20%20%20%20%20%20%20return%20cls(host%2Cport%2Cuser%2Cpwd%2Cdb%2Ccharset)%0A%0A%0A%20%20%20%20def%20process_item(self%2C%20item%2C%20spider)%3A%0A%0A%20%20%20%20%20%20%20%20sql%2Cdata%20%3D%20item.insert_data_to_db(dict(item))%0A%0A%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.cursor.execute(sql%2Cdata)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.client.commit()%0A%20%20%20%20%20%20%20%20%20%20%20%20print('%E6%8F%92%E5%85%A5%E6%88%90%E5%8A%9F')%0A%20%20%20%20%20%20%20%20except%20Exception%20as%20err%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(err)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.client.rollback()%0A%0A%20%20%20%20%20%20%20%20return%20item%0A%0A%20%20%20%20def%20close_spider(self%2Cspider)%3A%0A%20%20%20%20%20%20%20%20self.cursor.close()%0A%20%20%20%20%20%20%20%20self.client.close()%0A%60%60%60%0A%0A**%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9Asettings%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE**%0A%0A**settings.py%E8%AE%BE%E7%BD%AE%E6%96%87%E4%BB%B6**%0A%60%60%60%0Asettings%E9%87%8C%E9%9D%A2%E8%AE%BE%E7%BD%AE%E7%9B%B8%E5%85%B3%E5%8F%82%E6%95%B0%0A1.ROBOTSTXT_OBEY%20%3D%20False%20%E8%AE%BE%E7%BD%AE%E6%98%AF%E5%90%A6%E9%81%B5%E5%AE%88robot%E5%8D%8F%E8%AE%AE%0A2.DOWNLOAD_DELAY%20%3D%203%20%E8%AE%BE%E7%BD%AE%E4%B8%8B%E8%BD%BD%E5%BB%B6%E6%97%B6%0A3.%E8%AE%BE%E7%BD%AE%E5%85%A8%E5%B1%80%E7%9A%84Header%0ADEFAULT_REQUEST_HEADERS%20%3D%20%7B%0A%20%20%20%20'User-Agent'%3A'%20Mozilla%2F5.0%20(Macintosh%3B%20Intel%20Mac%20OS%20X%2010.12%3B%20rv%3A59.0)%20Gecko%2F20100101%20Firefox%2F59.0'%2C%0A%7D%0A%0A4.%E6%BF%80%E6%B4%BBpipelines%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%AE%A1%E9%81%93%0A%0AITEM_PIPELINES%20%3D%20%7B%0A%20%20%20'xiachufang.pipelines.XiachufangPipeline'%3A%20300%2C%0A%7D%0A%0A%23%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%0AMYSQL_HOST%20%3D%20'127.0.0.1'%0AMYSQL_PORT%20%3D%203306%0AMYSQL_USER%20%3D%20''%0AMYSQL_PWD%20%3D%20''%0AMYSQL_DB%20%3D%20''%0ACHARSET%20%3D%20'utf8'%0A%60%60%60%0A%0A**%E7%AC%AC%E4%BA%94%E6%AD%A5%EF%BC%9A%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F**%0A%0A**%E6%96%B9%E5%BC%8F%E4%B8%80**%0A%60%60%60%0A%E8%BF%90%E8%A1%8C%EF%BC%9A%0Ascrapy%20crawl%20xcfcrawlspider%0A%60%60%60%0A%0A**%E6%96%B9%E5%BC%8F%E4%BA%8C**%0A%0A**%E7%BC%96%E5%86%99main.py%E6%96%87%E4%BB%B6%E6%89%A7%E8%A1%8C**%0A%60%60%60%0Aimport%20os%2Csys%0Afrom%20scrapy.cmdline%20import%20execute%0A%0Asys.path.append(os.path.dirname(os.path.abspath(__file__)))%0Aexecute(%5B'scrapy'%2C'crawl'%2C'xcfcrawlspider'%5D)%0A%60%60%60%0A%0A**%E6%B3%A8%E6%84%8F%EF%BC%9A**%0A%60%60%60%0A%23%E6%8F%90%E5%8F%96%E5%8C%B9%E9%85%8D%E7%9A%84%E9%93%BE%E6%8E%A5%0Apage_lx%20%3D%20LinkExtractor(allow%20%3D%20('%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99'))%0A%0Arules%20%3D%20%5B%0A%20%20%20%20%23%E6%8F%90%E5%8F%96%E5%8C%B9%E9%85%8D%2C%E5%B9%B6%E4%BD%BF%E7%94%A8spider%E7%9A%84parse%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90%3B%E5%B9%B6%E8%B7%9F%E8%BF%9B%E9%93%BE%E6%8E%A5(%E6%B2%A1%E6%9C%89callback%E6%84%8F%E5%91%B3%E7%9D%80follow%E9%BB%98%E8%AE%A4%E4%B8%BATrue)%0A%20%20%20%20Rule(page_lx%2C%20callback%20%3D%20'parse'%2C%20follow%20%3D%20True)%0A%5D%0A%60%60%60%0A%0A**%E8%BF%99%E4%B9%88%E5%86%99%E5%AF%B9%E5%90%97%EF%BC%9F%E4%B8%8D%E5%AF%B9%EF%BC%81%E5%8D%83%E4%B8%87%E8%AE%B0%E4%BD%8F%20callback%20%E5%8D%83%E4%B8%87%E4%B8%8D%E8%83%BD%E5%86%99%20parse%EF%BC%8C%E5%86%8D%E6%AC%A1%E5%BC%BA%E8%B0%83%EF%BC%9A%E7%94%B1%E4%BA%8ECrawlSpider%E4%BD%BF%E7%94%A8parse%E6%96%B9%E6%B3%95%E6%9D%A5%E5%AE%9E%E7%8E%B0%E5%85%B6%E9%80%BB%E8%BE%91%EF%BC%8C%E5%A6%82%E6%9E%9C%E8%A6%86%E7%9B%96%E4%BA%86%20parse%E6%96%B9%E6%B3%95%EF%BC%8Ccrawl%20spider%E5%B0%86%E4%BC%9A%E8%BF%90%E8%A1%8C%E5%A4%B1%E8%B4%A5%E3%80%82**%0A%0A-----------------------------%0A%0A%23%23%20**%E4%BD%9C%E4%B8%9A**%0A%0A1.%E4%BD%BF%E7%94%A8%E9%80%9A%E7%94%A8%E7%88%AC%E8%99%AB%E5%AE%8C%E6%88%90**%E8%87%AA%E5%A6%82%E6%9C%89%E5%AE%B6**%E6%88%BF%E6%BA%90%E4%BF%A1%E6%81%AF%E7%9A%84%E6%8F%90%E5%8F%96%0A2.%E4%BD%BF%E7%94%A8%E9%80%9A%E7%94%A8%E7%88%AC%E8%99%AB%E5%AE%8C%E6%88%90**%E8%B5%B7%E7%82%B9%E4%B8%AD%E6%96%87%E7%BD%91**%E5%B0%8F%E8%AF%B4%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96%0A%0A</center></body></html>