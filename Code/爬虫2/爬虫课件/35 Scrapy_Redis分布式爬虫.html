<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.0.5 (458014)"/><meta name="altitude" content="36"/><meta name="author" content="李居豪"/><meta name="created" content="2019-05-29 14:29:59 +0000"/><meta name="latitude" content="39.63155572228862"/><meta name="longitude" content="116.0504265591249"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2019-06-27 00:43:42 +0000"/><meta name="content-class" content="yinxiang.markdown"/><title>35 Scrapy_Redis分布式爬虫</title></head><body><div style="font-size: 14px; margin: 0; padding: 0; width: 100%;"><p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><img src="35%20Scrapy_Redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB.resources/6FCB66BA-A5ED-4D66-B2D3-230BE88CC965.png" height="960" width="1252"/></p>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;">为什么要学习scrapy_redis</h4>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">Scrapy_redis在scrapy的基础上实现了更多，更强大的功能，具体体现在：reqeust去重，爬虫持久化，和轻松实现分布式</p>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;">安装</h3>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">pip3 install scrapy-redis
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">Scrapy-redis提供了下面四种组件（components）：(四种组件意味着这四个模块都要做相应的修改)</p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">Scheduler</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">Duplication Filter</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">Item Pipeline</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">Base Spider</li>
</ul>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;">Scrapy_redis是工作流程</h4>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><img src="https://i.loli.net/2018/12/17/5c178bee8f486.png" style="line-height: 160%; margin: 4px 0 10px; box-sizing: border-box; vertical-align: top; max-width: 100%;"/></p>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">源码自带项目说明：</strong></h3>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;">获取 scrapy-redis 源码文件</h4>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">git clone https://github.com/rolando/scrapy-redis.git
</code></pre>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;">官方的项目范例</h4>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">我们clone到的 scrapy-redis 源码中有自带一个example-project项目，这个项目包含3个spider，分别是dmoz, myspider_redis，mycrawler_redis。</p>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">一、dmoz (class DmozSpider(CrawlSpider))</strong></h4>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">注意：这里只是用到Redis的去重和保存功能,并没有实现分布式</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">这个爬虫继承的是CrawlSpider，它是用来说明Redis的持续性，当我们第一次运行dmoz爬虫，然后Ctrl + C停掉之后，再运行dmoz爬虫，之前的爬取记录是保留在Redis里的。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">分析起来，其实这就是一个 scrapy-redis 版 CrawlSpider 类，需要设置Rule规则，以及callback不能写parse()方法。<br/>
执行方式：</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">scrapy crawl dmoz
</code></pre>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">from scrapy.linkextractors import LinkExtractor
from scrapy.spiders import CrawlSpider, Rule


class DmozSpider(CrawlSpider):
    """Follow categories and extract links."""
    name = 'dmoz'
    allowed_domains = ['dmoz.org']
    start_urls = ['http://www.dmoz.org/']
　　
　　 #定义了一个url的提取规则，将满足条件的交给callback函数处理
    rules = [
        Rule(LinkExtractor(
            restrict_css=('.top-cat', '.sub-cat', '.cat-item')
        ), callback='parse_directory', follow=True),
    ]

    def parse_directory(self, response):
        for div in response.css('.title-and-desc'):
        　　#这里将获取到的内容交给引擎
            yield {
                'name': div.css('.site-title::text').extract_first(),
                'description': div.css('.site-descr::text').extract_first().strip(),
                'link': div.css('a::attr(href)').extract_first(),
            }
</code></pre>
<hr style="line-height: 160%; box-sizing: content-box; border-top: 1px solid #eee; margin: 16px 0;"/>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">二、myspider_redis (class MySpider(RedisSpider))</strong></h4>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">这个爬虫继承了RedisSpider， 它能够支持分布式的抓取，采用的是basic spider，需要写parse函数。<br/>
其次就是不再有start_urls了，取而代之的是redis_key，scrapy-redis将key从Redis里pop出来，成为请求的url地址。</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">from scrapy_redis.spiders import RedisSpider


class MySpider(RedisSpider):
    """Spider that reads urls from redis queue (myspider:start_urls)."""
    name = 'myspider_redis'
    #手动设置允许爬取的域
    allowed_domains = ['设置允许爬取的域']
    # 注意redis-key的格式：
    redis_key = 'myspider:start_urls'

    # 可选：等效于allowd_domains()，__init__方法按规定格式写，使用时只需要修改super()里的类名参数即可,一般不用
    def __init__(self, *args, **kwargs):
        # Dynamically define the allowed domains list.
        domain = kwargs.pop('domain', '')
        self.allowed_domains = filter(None, domain.split(','))

        # 修改这里的类名为当前类名
        super(MySpider, self).__init__(*args, **kwargs)

    def parse(self, response):
        return {
            'name': response.css('title::text').extract_first(),
            'url': response.url,
        }
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">注意：</strong><br/>
RedisSpider类 不需要写start_urls：</p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">scrapy-redis 一般直接写allowd_domains来指定需要爬取的域，也可以从在构造方法__init__()里动态定义爬虫爬取域范围（一般不用）。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">必须指定redis_key，即启动爬虫的命令，参考格式：redis_key = 'myspider:start_urls'</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">根据指定的格式，start_urls将在 Master端的 redis-cli 里 lpush 到 Redis数据库里，RedisSpider 将在数据库里获取start_urls。</p>
</li>
</ul>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">执行方式：</strong></p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">1.通过runspider方法执行爬虫的py文件（也可以分次执行多条），爬虫（们）将处于等待准备状态：</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">scrapy runspider myspider_redis.py
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">或者</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">scrapy crawl myspider_redis
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">2.在Master端的redis-cli输入push指令，参考格式(指定起始url)：</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">lpush myspider:start_urls http://www.dmoz.org/
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">3.Slaver端爬虫获取到请求，开始爬取。</li>
</ul>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">三、mycrawler_redis (class MyCrawler(RedisCrawlSpider))</strong></h3>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">这个RedisCrawlSpider类爬虫<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">继承了RedisCrawlSpider</strong>，能够支持分布式的抓取。因为采用的是crawlSpider，所以需要<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">遵守Rule规则</strong>，以及<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">callback不能写parse()方法</strong>。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">同样也不再有start_urls了，取而代之的是redis_key，scrapy-redis将key从Redis里pop出来，成为请求的url地址。</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">from scrapy.spiders import Rule
from scrapy.linkextractors import LinkExtractor

from scrapy_redis.spiders import RedisCrawlSpider


class MyCrawler(RedisCrawlSpider):

    """Spider that reads urls from redis queue (myspider:start_urls)."""

    name = 'mycrawler_redis'

    allowed_domains = ['设置允许爬取的域']
    redis_key = 'mycrawler:start_urls'

    rules = (
        # follow all links
        Rule(LinkExtractor(), callback='parse_page', follow=True),
    )

    # __init__方法必须按规定写，使用时只需要修改super()里的类名参数即可（一般不用）
    def __init__(self, *args, **kwargs):
        # Dynamically define the allowed domains list.
        domain = kwargs.pop('domain', '')
        self.allowed_domains = filter(None, domain.split(','))

        # 修改这里的类名为当前类名
        super(MyCrawler, self).__init__(*args, **kwargs)

    def parse_page(self, response):
        return {
            'name': response.css('title::text').extract_first(),
            'url': response.url,
        }
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">注意：</strong><br/>
同样的，RedisCrawlSpider类不需要写start_urls：</p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">scrapy-redis 一般直接写allowd_domains来指定需要爬取的域，也可以从在构造方法__init__()里动态定义爬虫爬取域范围（一般不用）。</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">必须指定redis_key，即启动爬虫的命令，参考格式：redis_key = 'myspider:start_urls'</p>
</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">
<p style="line-height: 160%; box-sizing: content-box; color: #333; margin: 0;">根据指定的格式，start_urls将在 Master端的 redis-cli 里 lpush 到 Redis数据库里，RedisSpider 将在数据库里获取start_urls。</p>
</li>
</ul>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">执行方式</strong>：</p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">1.通过runspider方法执行爬虫的py文件（也可以分次执行多条），爬虫（们）将处于等待准备状态：</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">scrapy runspider myspider_redis.py
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">或者</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">scrapy crawl myspider_redis
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">2.在Master端的redis-cli输入push指令，参考格式(指定起始url)：</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">lpush myspider:start_urls http://www.dmoz.org/
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">3.Slaver端爬虫获取到请求，开始爬取。</li>
</ul>
<h3 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 27px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">总结：</strong></h3>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">1</strong> 如果只是用到Redis的去重和保存功能，就选第一种；<br/>
<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">2</strong> 如果要写分布式，则根据情况，选择第二种、第三种；<br/>
<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">3</strong> 通常情况下，会选择用第三种方式编写深度聚焦爬虫。</p>
<h5 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 16px; color: #333;">要使用分布式 Scrapy_Redis Settings.py设置文件中需要做一下配置</h5>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">这里表示启用scrapy-redis里的去重组件，不实用scrapy默认的去重</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">DUPEFILTER_</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">使用了scrapy-redis里面的调度器组件，不使用scrapy默认的调度器</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">SCHEDULER = "scrapy_redis.scheduler.Scheduler"
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">允许暂停，redis请求的记录不会丢失，不清除Redis队列，可以恢复和暂停</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">SCHEDULER_PERSIST = True
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">下面这些是request的队列模式</li>
</ul>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">scrapy-redis默认的请求队列形式（有自己的优先级顺序）<br/>
是按照redis的有序集合排序出队列的</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">#SCHEDULER_QUEUE_</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">队列形式，请求先进先出</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">#SCHEDULER_QUEUE_</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">使用了栈的形式，请求先进后出</strong></p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">#SCHEDULER_QUEUE_</code></pre>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">ITEM_PIPELINES = {
    'example.pipelines.ExamplePipeline': 300,
    'scrapy_redis.pipelines.RedisPipeline': 400,
}
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">指定要存储的redis的主机的ip，默认存储在127.0.0.1</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">REDIS_HOST = 'redis的主机的ip'
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">定要存储的redis的主机的port，默认6379</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">REDIS_PORT = '6379'
</code></pre>
<h2 style="line-height: 160%; box-sizing: content-box; font-weight: 700; font-size: 34px; border-bottom: 1px solid #dbdbdb; color: #333;">导出分布式爬虫redis数据库中存储的数据</h2>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">数据爬回来了，但是放在Redis里没有处理。之前我们配置文件里面没有定制自己的ITEM_PIPELINES，而是使用了RedisPipeline，所以现在这些数据都被保存在redis中，所以我们需要另外做处理。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">在项目目录下可以看到一个process_items.py文件，这个文件就是scrapy-redis的example提供的从redis读取item进行处理的模版。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">假设我们要把redis中的items保存的数据读出来写进MongoDB或者MySQL，那么我们可以自己写一个process_profile.py文件，然后保持后台运行就可以不停地将爬回来的数据入库了。</p>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">将数据导出存储进入mongodb</strong></h4>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;"># -*- coding: utf-8 -*-

import json
import redis
import pymongo

def main():
    # 指定Redis数据库信息
    rediscli = redis.StrictRedis(host='localhost', port=6379, db=0)
    # 指定MongoDB数据库信息
    mongocli = pymongo.MongoClient(host='localhost', port=27017)
    # 指定数据库
    db = mongocli['数据库名称']
    # 指定集合
    sheet = db['集合名称']

    while True:
        # FIFO模式为 blpop，LIFO模式为 brpop，获取键值
        source, data = rediscli.blpop(“项目名:items")
        data = data.decode('utf-8')
        item = json.loads(data)
        try:
            sheet.insert(item)
            print ("Processing:insert successed" % item)
        except Exception as err:
            print ("err procesing: %r" % item)

if __name__ == '__main__':
    main()
</code></pre>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">将数据导出存入 MySQL</strong></h4>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">首先启动mysql<br/>
创建数据库和表</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;"># -*- coding: utf-8 -*-

import json
import redis
import pymysql

def main():
    # 指定redis数据库信息
    rediscli = redis.StrictRedis(host='localhost', port = 6379, db = 0)
    # 指定mysql数据库
    mysqlcli = pymysql.connect(host='localhost', user='用户', passwd='密码', db = '数据库', port=3306, charset='utf8')
    # 使用cursor()方法获取操作游标
    cur = mysqlcli.cursor()

    while True:
        # FIFO模式为 blpop，LIFO模式为 brpop，获取键值
        source, data = rediscli.blpop("redis中对应的文件夹:items")
        item = json.loads(data.decode('utf-8'))
        try:
            # 使用execute方法执行SQL INSERT语句
            cur.execute("sql语句"，['数据',....])
            # 提交sql事务
            mysqlcli.commit()
            print("inserted successed")
        except Exception as err:
            #插入失败
            print("Mysql Error",err)
            mysqlcli.rollback()

if __name__ == '__main__':
    main()
</code></pre>
</div><center style="display:none !important;visibility:collapse !important;height:0 !important;white-space:nowrap;width:100%;overflow:hidden">%20!%5B26ccaf7e125b874e1423def2a8638875.png%5D(en-resource%3A%2F%2Fdatabase%2F2465%3A1)%0A%23%23%23%23%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AD%A6%E4%B9%A0scrapy_redis%0A%0AScrapy_redis%E5%9C%A8scrapy%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8A%E5%AE%9E%E7%8E%B0%E4%BA%86%E6%9B%B4%E5%A4%9A%EF%BC%8C%E6%9B%B4%E5%BC%BA%E5%A4%A7%E7%9A%84%E5%8A%9F%E8%83%BD%EF%BC%8C%E5%85%B7%E4%BD%93%E4%BD%93%E7%8E%B0%E5%9C%A8%EF%BC%9Areqeust%E5%8E%BB%E9%87%8D%EF%BC%8C%E7%88%AC%E8%99%AB%E6%8C%81%E4%B9%85%E5%8C%96%EF%BC%8C%E5%92%8C%E8%BD%BB%E6%9D%BE%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%0A%0A%23%23%23%20%E5%AE%89%E8%A3%85%0A%60%60%60%0Apip3%20install%20scrapy-redis%0A%60%60%60%0A%0AScrapy-redis%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%8B%E9%9D%A2%E5%9B%9B%E7%A7%8D%E7%BB%84%E4%BB%B6%EF%BC%88components%EF%BC%89%EF%BC%9A(%E5%9B%9B%E7%A7%8D%E7%BB%84%E4%BB%B6%E6%84%8F%E5%91%B3%E7%9D%80%E8%BF%99%E5%9B%9B%E4%B8%AA%E6%A8%A1%E5%9D%97%E9%83%BD%E8%A6%81%E5%81%9A%E7%9B%B8%E5%BA%94%E7%9A%84%E4%BF%AE%E6%94%B9)%0A%0A-%20Scheduler%0A-%20Duplication%20Filter%0A-%20Item%20Pipeline%0A-%20Base%20Spider%0A%0A%0A%23%23%23%23%20Scrapy_redis%E6%98%AF%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%0A%0A!%5B%E5%9B%BE%E7%89%871%5D(https%3A%2F%2Fi.loli.net%2F2018%2F12%2F17%2F5c178bee8f486.png)%0A%0A%23%23%23%20**%E6%BA%90%E7%A0%81%E8%87%AA%E5%B8%A6%E9%A1%B9%E7%9B%AE%E8%AF%B4%E6%98%8E%EF%BC%9A**%0A%0A%23%23%23%23%20%E8%8E%B7%E5%8F%96%20scrapy-redis%20%E6%BA%90%E7%A0%81%E6%96%87%E4%BB%B6%0A%0A%60%60%60%0Agit%20clone%20https%3A%2F%2Fgithub.com%2Frolando%2Fscrapy-redis.git%0A%60%60%60%0A%23%23%23%23%20%E5%AE%98%E6%96%B9%E7%9A%84%E9%A1%B9%E7%9B%AE%E8%8C%83%E4%BE%8B%0A%0A%E6%88%91%E4%BB%ACclone%E5%88%B0%E7%9A%84%20scrapy-redis%20%E6%BA%90%E7%A0%81%E4%B8%AD%E6%9C%89%E8%87%AA%E5%B8%A6%E4%B8%80%E4%B8%AAexample-project%E9%A1%B9%E7%9B%AE%EF%BC%8C%E8%BF%99%E4%B8%AA%E9%A1%B9%E7%9B%AE%E5%8C%85%E5%90%AB3%E4%B8%AAspider%EF%BC%8C%E5%88%86%E5%88%AB%E6%98%AFdmoz%2C%20myspider_redis%EF%BC%8Cmycrawler_redis%E3%80%82%0A%0A%23%23%23%23%20**%E4%B8%80%E3%80%81dmoz%20(class%20DmozSpider(CrawlSpider))**%0A%0A**%E6%B3%A8%E6%84%8F%EF%BC%9A%E8%BF%99%E9%87%8C%E5%8F%AA%E6%98%AF%E7%94%A8%E5%88%B0Redis%E7%9A%84%E5%8E%BB%E9%87%8D%E5%92%8C%E4%BF%9D%E5%AD%98%E5%8A%9F%E8%83%BD%2C%E5%B9%B6%E6%B2%A1%E6%9C%89%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F**%0A%0A%E8%BF%99%E4%B8%AA%E7%88%AC%E8%99%AB%E7%BB%A7%E6%89%BF%E7%9A%84%E6%98%AFCrawlSpider%EF%BC%8C%E5%AE%83%E6%98%AF%E7%94%A8%E6%9D%A5%E8%AF%B4%E6%98%8ERedis%E7%9A%84%E6%8C%81%E7%BB%AD%E6%80%A7%EF%BC%8C%E5%BD%93%E6%88%91%E4%BB%AC%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%BF%90%E8%A1%8Cdmoz%E7%88%AC%E8%99%AB%EF%BC%8C%E7%84%B6%E5%90%8ECtrl%20%2B%20C%E5%81%9C%E6%8E%89%E4%B9%8B%E5%90%8E%EF%BC%8C%E5%86%8D%E8%BF%90%E8%A1%8Cdmoz%E7%88%AC%E8%99%AB%EF%BC%8C%E4%B9%8B%E5%89%8D%E7%9A%84%E7%88%AC%E5%8F%96%E8%AE%B0%E5%BD%95%E6%98%AF%E4%BF%9D%E7%95%99%E5%9C%A8Redis%E9%87%8C%E7%9A%84%E3%80%82%0A%0A%E5%88%86%E6%9E%90%E8%B5%B7%E6%9D%A5%EF%BC%8C%E5%85%B6%E5%AE%9E%E8%BF%99%E5%B0%B1%E6%98%AF%E4%B8%80%E4%B8%AA%20scrapy-redis%20%E7%89%88%20CrawlSpider%20%E7%B1%BB%EF%BC%8C%E9%9C%80%E8%A6%81%E8%AE%BE%E7%BD%AERule%E8%A7%84%E5%88%99%EF%BC%8C%E4%BB%A5%E5%8F%8Acallback%E4%B8%8D%E8%83%BD%E5%86%99parse()%E6%96%B9%E6%B3%95%E3%80%82%0A%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8F%EF%BC%9A%0A%60%60%60%0Ascrapy%20crawl%20dmoz%0A%60%60%60%0A%0A%60%60%60%0Afrom%20scrapy.linkextractors%20import%20LinkExtractor%0Afrom%20scrapy.spiders%20import%20CrawlSpider%2C%20Rule%0A%0A%0Aclass%20DmozSpider(CrawlSpider)%3A%0A%20%20%20%20%22%22%22Follow%20categories%20and%20extract%20links.%22%22%22%0A%20%20%20%20name%20%3D%20'dmoz'%0A%20%20%20%20allowed_domains%20%3D%20%5B'dmoz.org'%5D%0A%20%20%20%20start_urls%20%3D%20%5B'http%3A%2F%2Fwww.dmoz.org%2F'%5D%0A%E3%80%80%E3%80%80%0A%E3%80%80%E3%80%80%20%23%E5%AE%9A%E4%B9%89%E4%BA%86%E4%B8%80%E4%B8%AAurl%E7%9A%84%E6%8F%90%E5%8F%96%E8%A7%84%E5%88%99%EF%BC%8C%E5%B0%86%E6%BB%A1%E8%B6%B3%E6%9D%A1%E4%BB%B6%E7%9A%84%E4%BA%A4%E7%BB%99callback%E5%87%BD%E6%95%B0%E5%A4%84%E7%90%86%0A%20%20%20%20rules%20%3D%20%5B%0A%20%20%20%20%20%20%20%20Rule(LinkExtractor(%0A%20%20%20%20%20%20%20%20%20%20%20%20restrict_css%3D('.top-cat'%2C%20'.sub-cat'%2C%20'.cat-item')%0A%20%20%20%20%20%20%20%20)%2C%20callback%3D'parse_directory'%2C%20follow%3DTrue)%2C%0A%20%20%20%20%5D%0A%0A%20%20%20%20def%20parse_directory(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20for%20div%20in%20response.css('.title-and-desc')%3A%0A%20%20%20%20%20%20%20%20%E3%80%80%E3%80%80%23%E8%BF%99%E9%87%8C%E5%B0%86%E8%8E%B7%E5%8F%96%E5%88%B0%E7%9A%84%E5%86%85%E5%AE%B9%E4%BA%A4%E7%BB%99%E5%BC%95%E6%93%8E%0A%20%20%20%20%20%20%20%20%20%20%20%20yield%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'name'%3A%20div.css('.site-title%3A%3Atext').extract_first()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'description'%3A%20div.css('.site-descr%3A%3Atext').extract_first().strip()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'link'%3A%20div.css('a%3A%3Aattr(href)').extract_first()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%60%60%60%0A-------------------%0A%0A%23%23%23%23%20**%E4%BA%8C%E3%80%81myspider_redis%20(class%20MySpider(RedisSpider))**%0A%0A%E8%BF%99%E4%B8%AA%E7%88%AC%E8%99%AB%E7%BB%A7%E6%89%BF%E4%BA%86RedisSpider%EF%BC%8C%20%E5%AE%83%E8%83%BD%E5%A4%9F%E6%94%AF%E6%8C%81%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E6%8A%93%E5%8F%96%EF%BC%8C%E9%87%87%E7%94%A8%E7%9A%84%E6%98%AFbasic%20spider%EF%BC%8C%E9%9C%80%E8%A6%81%E5%86%99parse%E5%87%BD%E6%95%B0%E3%80%82%0A%E5%85%B6%E6%AC%A1%E5%B0%B1%E6%98%AF%E4%B8%8D%E5%86%8D%E6%9C%89start_urls%E4%BA%86%EF%BC%8C%E5%8F%96%E8%80%8C%E4%BB%A3%E4%B9%8B%E7%9A%84%E6%98%AFredis_key%EF%BC%8Cscrapy-redis%E5%B0%86key%E4%BB%8ERedis%E9%87%8Cpop%E5%87%BA%E6%9D%A5%EF%BC%8C%E6%88%90%E4%B8%BA%E8%AF%B7%E6%B1%82%E7%9A%84url%E5%9C%B0%E5%9D%80%E3%80%82%0A%60%60%60%0Afrom%20scrapy_redis.spiders%20import%20RedisSpider%0A%0A%0Aclass%20MySpider(RedisSpider)%3A%0A%20%20%20%20%22%22%22Spider%20that%20reads%20urls%20from%20redis%20queue%20(myspider%3Astart_urls).%22%22%22%0A%20%20%20%20name%20%3D%20'myspider_redis'%0A%20%20%20%20%23%E6%89%8B%E5%8A%A8%E8%AE%BE%E7%BD%AE%E5%85%81%E8%AE%B8%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F%0A%20%20%20%20allowed_domains%20%3D%20%5B'%E8%AE%BE%E7%BD%AE%E5%85%81%E8%AE%B8%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F'%5D%0A%20%20%20%20%23%20%E6%B3%A8%E6%84%8Fredis-key%E7%9A%84%E6%A0%BC%E5%BC%8F%EF%BC%9A%0A%20%20%20%20redis_key%20%3D%20'myspider%3Astart_urls'%0A%0A%20%20%20%20%23%20%E5%8F%AF%E9%80%89%EF%BC%9A%E7%AD%89%E6%95%88%E4%BA%8Eallowd_domains()%EF%BC%8C__init__%E6%96%B9%E6%B3%95%E6%8C%89%E8%A7%84%E5%AE%9A%E6%A0%BC%E5%BC%8F%E5%86%99%EF%BC%8C%E4%BD%BF%E7%94%A8%E6%97%B6%E5%8F%AA%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9super()%E9%87%8C%E7%9A%84%E7%B1%BB%E5%90%8D%E5%8F%82%E6%95%B0%E5%8D%B3%E5%8F%AF%2C%E4%B8%80%E8%88%AC%E4%B8%8D%E7%94%A8%0A%20%20%20%20def%20__init__(self%2C%20*args%2C%20**kwargs)%3A%0A%20%20%20%20%20%20%20%20%23%20Dynamically%20define%20the%20allowed%20domains%20list.%0A%20%20%20%20%20%20%20%20domain%20%3D%20kwargs.pop('domain'%2C%20'')%0A%20%20%20%20%20%20%20%20self.allowed_domains%20%3D%20filter(None%2C%20domain.split('%2C'))%0A%0A%20%20%20%20%20%20%20%20%23%20%E4%BF%AE%E6%94%B9%E8%BF%99%E9%87%8C%E7%9A%84%E7%B1%BB%E5%90%8D%E4%B8%BA%E5%BD%93%E5%89%8D%E7%B1%BB%E5%90%8D%0A%20%20%20%20%20%20%20%20super(MySpider%2C%20self).__init__(*args%2C%20**kwargs)%0A%0A%20%20%20%20def%20parse(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20return%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20'name'%3A%20response.css('title%3A%3Atext').extract_first()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'url'%3A%20response.url%2C%0A%20%20%20%20%20%20%20%20%7D%0A%60%60%60%0A**%E6%B3%A8%E6%84%8F%EF%BC%9A**%0ARedisSpider%E7%B1%BB%20%E4%B8%8D%E9%9C%80%E8%A6%81%E5%86%99start_urls%EF%BC%9A%0A%0A-%20scrapy-redis%20%E4%B8%80%E8%88%AC%E7%9B%B4%E6%8E%A5%E5%86%99allowd_domains%E6%9D%A5%E6%8C%87%E5%AE%9A%E9%9C%80%E8%A6%81%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E4%BB%8E%E5%9C%A8%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95__init__()%E9%87%8C%E5%8A%A8%E6%80%81%E5%AE%9A%E4%B9%89%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9F%9F%E8%8C%83%E5%9B%B4%EF%BC%88%E4%B8%80%E8%88%AC%E4%B8%8D%E7%94%A8%EF%BC%89%E3%80%82%0A%0A-%20%E5%BF%85%E9%A1%BB%E6%8C%87%E5%AE%9Aredis_key%EF%BC%8C%E5%8D%B3%E5%90%AF%E5%8A%A8%E7%88%AC%E8%99%AB%E7%9A%84%E5%91%BD%E4%BB%A4%EF%BC%8C%E5%8F%82%E8%80%83%E6%A0%BC%E5%BC%8F%EF%BC%9Aredis_key%20%3D%20'myspider%3Astart_urls'%0A%0A-%20%E6%A0%B9%E6%8D%AE%E6%8C%87%E5%AE%9A%E7%9A%84%E6%A0%BC%E5%BC%8F%EF%BC%8Cstart_urls%E5%B0%86%E5%9C%A8%20Master%E7%AB%AF%E7%9A%84%20redis-cli%20%E9%87%8C%20lpush%20%E5%88%B0%20Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E9%87%8C%EF%BC%8CRedisSpider%20%E5%B0%86%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E9%87%8C%E8%8E%B7%E5%8F%96start_urls%E3%80%82%0A%0A**%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8F%EF%BC%9A**%0A%0A-%201.%E9%80%9A%E8%BF%87runspider%E6%96%B9%E6%B3%95%E6%89%A7%E8%A1%8C%E7%88%AC%E8%99%AB%E7%9A%84py%E6%96%87%E4%BB%B6%EF%BC%88%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%88%86%E6%AC%A1%E6%89%A7%E8%A1%8C%E5%A4%9A%E6%9D%A1%EF%BC%89%EF%BC%8C%E7%88%AC%E8%99%AB%EF%BC%88%E4%BB%AC%EF%BC%89%E5%B0%86%E5%A4%84%E4%BA%8E%E7%AD%89%E5%BE%85%E5%87%86%E5%A4%87%E7%8A%B6%E6%80%81%EF%BC%9A%0A%60%60%60%0Ascrapy%20runspider%20myspider_redis.py%0A%60%60%60%0A%E6%88%96%E8%80%85%0A%60%60%60%0Ascrapy%20crawl%20myspider_redis%0A%60%60%60%0A%0A-%202.%E5%9C%A8Master%E7%AB%AF%E7%9A%84redis-cli%E8%BE%93%E5%85%A5push%E6%8C%87%E4%BB%A4%EF%BC%8C%E5%8F%82%E8%80%83%E6%A0%BC%E5%BC%8F(%E6%8C%87%E5%AE%9A%E8%B5%B7%E5%A7%8Burl)%EF%BC%9A%0A%60%60%60%0Alpush%20myspider%3Astart_urls%20http%3A%2F%2Fwww.dmoz.org%2F%0A%60%60%60%0A%0A-%203.Slaver%E7%AB%AF%E7%88%AC%E8%99%AB%E8%8E%B7%E5%8F%96%E5%88%B0%E8%AF%B7%E6%B1%82%EF%BC%8C%E5%BC%80%E5%A7%8B%E7%88%AC%E5%8F%96%E3%80%82%0A%0A%23%23%23%20**%E4%B8%89%E3%80%81mycrawler_redis%20(class%20MyCrawler(RedisCrawlSpider))**%0A%0A%E8%BF%99%E4%B8%AARedisCrawlSpider%E7%B1%BB%E7%88%AC%E8%99%AB**%E7%BB%A7%E6%89%BF%E4%BA%86RedisCrawlSpider**%EF%BC%8C%E8%83%BD%E5%A4%9F%E6%94%AF%E6%8C%81%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E6%8A%93%E5%8F%96%E3%80%82%E5%9B%A0%E4%B8%BA%E9%87%87%E7%94%A8%E7%9A%84%E6%98%AFcrawlSpider%EF%BC%8C%E6%89%80%E4%BB%A5%E9%9C%80%E8%A6%81**%E9%81%B5%E5%AE%88Rule%E8%A7%84%E5%88%99**%EF%BC%8C%E4%BB%A5%E5%8F%8A**callback%E4%B8%8D%E8%83%BD%E5%86%99parse()%E6%96%B9%E6%B3%95**%E3%80%82%0A%0A%E5%90%8C%E6%A0%B7%E4%B9%9F%E4%B8%8D%E5%86%8D%E6%9C%89start_urls%E4%BA%86%EF%BC%8C%E5%8F%96%E8%80%8C%E4%BB%A3%E4%B9%8B%E7%9A%84%E6%98%AFredis_key%EF%BC%8Cscrapy-redis%E5%B0%86key%E4%BB%8ERedis%E9%87%8Cpop%E5%87%BA%E6%9D%A5%EF%BC%8C%E6%88%90%E4%B8%BA%E8%AF%B7%E6%B1%82%E7%9A%84url%E5%9C%B0%E5%9D%80%E3%80%82%0A%60%60%60%0Afrom%20scrapy.spiders%20import%20Rule%0Afrom%20scrapy.linkextractors%20import%20LinkExtractor%0A%0Afrom%20scrapy_redis.spiders%20import%20RedisCrawlSpider%0A%0A%0Aclass%20MyCrawler(RedisCrawlSpider)%3A%0A%0A%20%20%20%20%22%22%22Spider%20that%20reads%20urls%20from%20redis%20queue%20(myspider%3Astart_urls).%22%22%22%0A%0A%20%20%20%20name%20%3D%20'mycrawler_redis'%0A%0A%20%20%20%20allowed_domains%20%3D%20%5B'%E8%AE%BE%E7%BD%AE%E5%85%81%E8%AE%B8%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F'%5D%0A%20%20%20%20redis_key%20%3D%20'mycrawler%3Astart_urls'%0A%0A%20%20%20%20rules%20%3D%20(%0A%20%20%20%20%20%20%20%20%23%20follow%20all%20links%0A%20%20%20%20%20%20%20%20Rule(LinkExtractor()%2C%20callback%3D'parse_page'%2C%20follow%3DTrue)%2C%0A%20%20%20%20)%0A%0A%20%20%20%20%23%20__init__%E6%96%B9%E6%B3%95%E5%BF%85%E9%A1%BB%E6%8C%89%E8%A7%84%E5%AE%9A%E5%86%99%EF%BC%8C%E4%BD%BF%E7%94%A8%E6%97%B6%E5%8F%AA%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9super()%E9%87%8C%E7%9A%84%E7%B1%BB%E5%90%8D%E5%8F%82%E6%95%B0%E5%8D%B3%E5%8F%AF%EF%BC%88%E4%B8%80%E8%88%AC%E4%B8%8D%E7%94%A8%EF%BC%89%0A%20%20%20%20def%20__init__(self%2C%20*args%2C%20**kwargs)%3A%0A%20%20%20%20%20%20%20%20%23%20Dynamically%20define%20the%20allowed%20domains%20list.%0A%20%20%20%20%20%20%20%20domain%20%3D%20kwargs.pop('domain'%2C%20'')%0A%20%20%20%20%20%20%20%20self.allowed_domains%20%3D%20filter(None%2C%20domain.split('%2C'))%0A%0A%20%20%20%20%20%20%20%20%23%20%E4%BF%AE%E6%94%B9%E8%BF%99%E9%87%8C%E7%9A%84%E7%B1%BB%E5%90%8D%E4%B8%BA%E5%BD%93%E5%89%8D%E7%B1%BB%E5%90%8D%0A%20%20%20%20%20%20%20%20super(MyCrawler%2C%20self).__init__(*args%2C%20**kwargs)%0A%0A%20%20%20%20def%20parse_page(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20return%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20'name'%3A%20response.css('title%3A%3Atext').extract_first()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'url'%3A%20response.url%2C%0A%20%20%20%20%20%20%20%20%7D%0A%60%60%60%0A%0A**%E6%B3%A8%E6%84%8F%EF%BC%9A**%0A%E5%90%8C%E6%A0%B7%E7%9A%84%EF%BC%8CRedisCrawlSpider%E7%B1%BB%E4%B8%8D%E9%9C%80%E8%A6%81%E5%86%99start_urls%EF%BC%9A%0A%0A-%20scrapy-redis%20%E4%B8%80%E8%88%AC%E7%9B%B4%E6%8E%A5%E5%86%99allowd_domains%E6%9D%A5%E6%8C%87%E5%AE%9A%E9%9C%80%E8%A6%81%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E4%BB%8E%E5%9C%A8%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95__init__()%E9%87%8C%E5%8A%A8%E6%80%81%E5%AE%9A%E4%B9%89%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E5%9F%9F%E8%8C%83%E5%9B%B4%EF%BC%88%E4%B8%80%E8%88%AC%E4%B8%8D%E7%94%A8%EF%BC%89%E3%80%82%0A%0A-%20%E5%BF%85%E9%A1%BB%E6%8C%87%E5%AE%9Aredis_key%EF%BC%8C%E5%8D%B3%E5%90%AF%E5%8A%A8%E7%88%AC%E8%99%AB%E7%9A%84%E5%91%BD%E4%BB%A4%EF%BC%8C%E5%8F%82%E8%80%83%E6%A0%BC%E5%BC%8F%EF%BC%9Aredis_key%20%3D%20'myspider%3Astart_urls'%0A%0A-%20%E6%A0%B9%E6%8D%AE%E6%8C%87%E5%AE%9A%E7%9A%84%E6%A0%BC%E5%BC%8F%EF%BC%8Cstart_urls%E5%B0%86%E5%9C%A8%20Master%E7%AB%AF%E7%9A%84%20redis-cli%20%E9%87%8C%20lpush%20%E5%88%B0%20Redis%E6%95%B0%E6%8D%AE%E5%BA%93%E9%87%8C%EF%BC%8CRedisSpider%20%E5%B0%86%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E9%87%8C%E8%8E%B7%E5%8F%96start_urls%E3%80%82%0A%0A**%E6%89%A7%E8%A1%8C%E6%96%B9%E5%BC%8F**%EF%BC%9A%0A-%201.%E9%80%9A%E8%BF%87runspider%E6%96%B9%E6%B3%95%E6%89%A7%E8%A1%8C%E7%88%AC%E8%99%AB%E7%9A%84py%E6%96%87%E4%BB%B6%EF%BC%88%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%88%86%E6%AC%A1%E6%89%A7%E8%A1%8C%E5%A4%9A%E6%9D%A1%EF%BC%89%EF%BC%8C%E7%88%AC%E8%99%AB%EF%BC%88%E4%BB%AC%EF%BC%89%E5%B0%86%E5%A4%84%E4%BA%8E%E7%AD%89%E5%BE%85%E5%87%86%E5%A4%87%E7%8A%B6%E6%80%81%EF%BC%9A%0A%60%60%60%0Ascrapy%20runspider%20myspider_redis.py%0A%60%60%60%0A%E6%88%96%E8%80%85%0A%60%60%60%0Ascrapy%20crawl%20myspider_redis%0A%60%60%60%0A%0A-%202.%E5%9C%A8Master%E7%AB%AF%E7%9A%84redis-cli%E8%BE%93%E5%85%A5push%E6%8C%87%E4%BB%A4%EF%BC%8C%E5%8F%82%E8%80%83%E6%A0%BC%E5%BC%8F(%E6%8C%87%E5%AE%9A%E8%B5%B7%E5%A7%8Burl)%EF%BC%9A%0A%60%60%60%0Alpush%20myspider%3Astart_urls%20http%3A%2F%2Fwww.dmoz.org%2F%0A%60%60%60%0A%0A-%203.Slaver%E7%AB%AF%E7%88%AC%E8%99%AB%E8%8E%B7%E5%8F%96%E5%88%B0%E8%AF%B7%E6%B1%82%EF%BC%8C%E5%BC%80%E5%A7%8B%E7%88%AC%E5%8F%96%E3%80%82%0A%0A%23%23%23%20**%E6%80%BB%E7%BB%93%EF%BC%9A**%0A%0A**1**%20%E5%A6%82%E6%9E%9C%E5%8F%AA%E6%98%AF%E7%94%A8%E5%88%B0Redis%E7%9A%84%E5%8E%BB%E9%87%8D%E5%92%8C%E4%BF%9D%E5%AD%98%E5%8A%9F%E8%83%BD%EF%BC%8C%E5%B0%B1%E9%80%89%E7%AC%AC%E4%B8%80%E7%A7%8D%EF%BC%9B%0A**2**%20%E5%A6%82%E6%9E%9C%E8%A6%81%E5%86%99%E5%88%86%E5%B8%83%E5%BC%8F%EF%BC%8C%E5%88%99%E6%A0%B9%E6%8D%AE%E6%83%85%E5%86%B5%EF%BC%8C%E9%80%89%E6%8B%A9%E7%AC%AC%E4%BA%8C%E7%A7%8D%E3%80%81%E7%AC%AC%E4%B8%89%E7%A7%8D%EF%BC%9B%0A**3**%20%E9%80%9A%E5%B8%B8%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8C%E4%BC%9A%E9%80%89%E6%8B%A9%E7%94%A8%E7%AC%AC%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F%E7%BC%96%E5%86%99%E6%B7%B1%E5%BA%A6%E8%81%9A%E7%84%A6%E7%88%AC%E8%99%AB%E3%80%82%0A%0A%0A%0A%23%23%23%23%23%20%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%B8%83%E5%BC%8F%20Scrapy_Redis%20Settings.py%E8%AE%BE%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E9%9C%80%E8%A6%81%E5%81%9A%E4%B8%80%E4%B8%8B%E9%85%8D%E7%BD%AE%0A%0A%0A-%20%E8%BF%99%E9%87%8C%E8%A1%A8%E7%A4%BA%E5%90%AF%E7%94%A8scrapy-redis%E9%87%8C%E7%9A%84%E5%8E%BB%E9%87%8D%E7%BB%84%E4%BB%B6%EF%BC%8C%E4%B8%8D%E5%AE%9E%E7%94%A8scrapy%E9%BB%98%E8%AE%A4%E7%9A%84%E5%8E%BB%E9%87%8D%0A%60%60%60%0ADUPEFILTER_CLASS%20%3D%20%22scrapy_redis.dupefilter.RFPDupeFilter%22%0A%60%60%60%0A%0A-%20%E4%BD%BF%E7%94%A8%E4%BA%86scrapy-redis%E9%87%8C%E9%9D%A2%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8%E7%BB%84%E4%BB%B6%EF%BC%8C%E4%B8%8D%E4%BD%BF%E7%94%A8scrapy%E9%BB%98%E8%AE%A4%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8%0A%60%60%60%0ASCHEDULER%20%3D%20%22scrapy_redis.scheduler.Scheduler%22%0A%60%60%60%0A%0A-%20%E5%85%81%E8%AE%B8%E6%9A%82%E5%81%9C%EF%BC%8Credis%E8%AF%B7%E6%B1%82%E7%9A%84%E8%AE%B0%E5%BD%95%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1%EF%BC%8C%E4%B8%8D%E6%B8%85%E9%99%A4Redis%E9%98%9F%E5%88%97%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%81%A2%E5%A4%8D%E5%92%8C%E6%9A%82%E5%81%9C%0A%60%60%60%0ASCHEDULER_PERSIST%20%3D%20True%0A%60%60%60%0A%0A%0A-%20%E4%B8%8B%E9%9D%A2%E8%BF%99%E4%BA%9B%E6%98%AFrequest%E7%9A%84%E9%98%9F%E5%88%97%E6%A8%A1%E5%BC%8F%0A%0A**scrapy-redis%E9%BB%98%E8%AE%A4%E7%9A%84%E8%AF%B7%E6%B1%82%E9%98%9F%E5%88%97%E5%BD%A2%E5%BC%8F%EF%BC%88%E6%9C%89%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BC%98%E5%85%88%E7%BA%A7%E9%A1%BA%E5%BA%8F%EF%BC%89%0A%E6%98%AF%E6%8C%89%E7%85%A7redis%E7%9A%84%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E6%8E%92%E5%BA%8F%E5%87%BA%E9%98%9F%E5%88%97%E7%9A%84**%0A%60%60%60%0A%23SCHEDULER_QUEUE_CLASS%20%3D%20%22scrapy_redis.queue.SpiderPriorityQueue%22%0A%60%60%60%0A%0A**%E9%98%9F%E5%88%97%E5%BD%A2%E5%BC%8F%EF%BC%8C%E8%AF%B7%E6%B1%82%E5%85%88%E8%BF%9B%E5%85%88%E5%87%BA**%0A%60%60%60%0A%23SCHEDULER_QUEUE_CLASS%20%3D%20%22scrapy_redis.queue.SpiderQueue%22%0A%60%60%60%0A%0A**%E4%BD%BF%E7%94%A8%E4%BA%86%E6%A0%88%E7%9A%84%E5%BD%A2%E5%BC%8F%EF%BC%8C%E8%AF%B7%E6%B1%82%E5%85%88%E8%BF%9B%E5%90%8E%E5%87%BA**%0A%60%60%60%0A%23SCHEDULER_QUEUE_CLASS%20%3D%20%22scrapy_redis.queue.SpiderStack%22%0A%60%60%60%0A%0A%60%60%60%0AITEM_PIPELINES%20%3D%20%7B%0A%20%20%20%20'example.pipelines.ExamplePipeline'%3A%20300%2C%0A%20%20%20%20'scrapy_redis.pipelines.RedisPipeline'%3A%20400%2C%0A%7D%0A%60%60%60%0A%0A-%20%E6%8C%87%E5%AE%9A%E8%A6%81%E5%AD%98%E5%82%A8%E7%9A%84redis%E7%9A%84%E4%B8%BB%E6%9C%BA%E7%9A%84ip%EF%BC%8C%E9%BB%98%E8%AE%A4%E5%AD%98%E5%82%A8%E5%9C%A8127.0.0.1%0A%60%60%60%0AREDIS_HOST%20%3D%20'redis%E7%9A%84%E4%B8%BB%E6%9C%BA%E7%9A%84ip'%0A%60%60%60%0A-%20%E5%AE%9A%E8%A6%81%E5%AD%98%E5%82%A8%E7%9A%84redis%E7%9A%84%E4%B8%BB%E6%9C%BA%E7%9A%84port%EF%BC%8C%E9%BB%98%E8%AE%A46379%0A%60%60%60%0AREDIS_PORT%20%3D%20'6379'%0A%60%60%60%0A%0A%0A%23%23%20%E5%AF%BC%E5%87%BA%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%ABredis%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E5%AD%98%E5%82%A8%E7%9A%84%E6%95%B0%E6%8D%AE%0A%0A%E6%95%B0%E6%8D%AE%E7%88%AC%E5%9B%9E%E6%9D%A5%E4%BA%86%EF%BC%8C%E4%BD%86%E6%98%AF%E6%94%BE%E5%9C%A8Redis%E9%87%8C%E6%B2%A1%E6%9C%89%E5%A4%84%E7%90%86%E3%80%82%E4%B9%8B%E5%89%8D%E6%88%91%E4%BB%AC%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E9%87%8C%E9%9D%A2%E6%B2%A1%E6%9C%89%E5%AE%9A%E5%88%B6%E8%87%AA%E5%B7%B1%E7%9A%84ITEM_PIPELINES%EF%BC%8C%E8%80%8C%E6%98%AF%E4%BD%BF%E7%94%A8%E4%BA%86RedisPipeline%EF%BC%8C%E6%89%80%E4%BB%A5%E7%8E%B0%E5%9C%A8%E8%BF%99%E4%BA%9B%E6%95%B0%E6%8D%AE%E9%83%BD%E8%A2%AB%E4%BF%9D%E5%AD%98%E5%9C%A8redis%E4%B8%AD%EF%BC%8C%E6%89%80%E4%BB%A5%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81%E5%8F%A6%E5%A4%96%E5%81%9A%E5%A4%84%E7%90%86%E3%80%82%0A%0A%E5%9C%A8%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E4%B8%80%E4%B8%AAprocess_items.py%E6%96%87%E4%BB%B6%EF%BC%8C%E8%BF%99%E4%B8%AA%E6%96%87%E4%BB%B6%E5%B0%B1%E6%98%AFscrapy-redis%E7%9A%84example%E6%8F%90%E4%BE%9B%E7%9A%84%E4%BB%8Eredis%E8%AF%BB%E5%8F%96item%E8%BF%9B%E8%A1%8C%E5%A4%84%E7%90%86%E7%9A%84%E6%A8%A1%E7%89%88%E3%80%82%0A%0A%E5%81%87%E8%AE%BE%E6%88%91%E4%BB%AC%E8%A6%81%E6%8A%8Aredis%E4%B8%AD%E7%9A%84items%E4%BF%9D%E5%AD%98%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%87%BA%E6%9D%A5%E5%86%99%E8%BF%9BMongoDB%E6%88%96%E8%80%85MySQL%EF%BC%8C%E9%82%A3%E4%B9%88%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E8%87%AA%E5%B7%B1%E5%86%99%E4%B8%80%E4%B8%AAprocess_profile.py%E6%96%87%E4%BB%B6%EF%BC%8C%E7%84%B6%E5%90%8E%E4%BF%9D%E6%8C%81%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C%E5%B0%B1%E5%8F%AF%E4%BB%A5%E4%B8%8D%E5%81%9C%E5%9C%B0%E5%B0%86%E7%88%AC%E5%9B%9E%E6%9D%A5%E7%9A%84%E6%95%B0%E6%8D%AE%E5%85%A5%E5%BA%93%E4%BA%86%E3%80%82%0A%0A%23%23%23%23%20**%E5%B0%86%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA%E5%AD%98%E5%82%A8%E8%BF%9B%E5%85%A5mongodb**%0A%0A%60%60%60%0A%23%20-*-%20coding%3A%20utf-8%20-*-%0A%0Aimport%20json%0Aimport%20redis%0Aimport%20pymongo%0A%0Adef%20main()%3A%0A%20%20%20%20%23%20%E6%8C%87%E5%AE%9ARedis%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%A1%E6%81%AF%0A%20%20%20%20rediscli%20%3D%20redis.StrictRedis(host%3D'localhost'%2C%20port%3D6379%2C%20db%3D0)%0A%20%20%20%20%23%20%E6%8C%87%E5%AE%9AMongoDB%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%A1%E6%81%AF%0A%20%20%20%20mongocli%20%3D%20pymongo.MongoClient(host%3D'localhost'%2C%20port%3D27017)%0A%20%20%20%20%23%20%E6%8C%87%E5%AE%9A%E6%95%B0%E6%8D%AE%E5%BA%93%0A%20%20%20%20db%20%3D%20mongocli%5B'%E6%95%B0%E6%8D%AE%E5%BA%93%E5%90%8D%E7%A7%B0'%5D%0A%20%20%20%20%23%20%E6%8C%87%E5%AE%9A%E9%9B%86%E5%90%88%0A%20%20%20%20sheet%20%3D%20db%5B'%E9%9B%86%E5%90%88%E5%90%8D%E7%A7%B0'%5D%0A%0A%20%20%20%20while%20True%3A%0A%20%20%20%20%20%20%20%20%23%20FIFO%E6%A8%A1%E5%BC%8F%E4%B8%BA%20blpop%EF%BC%8CLIFO%E6%A8%A1%E5%BC%8F%E4%B8%BA%20brpop%EF%BC%8C%E8%8E%B7%E5%8F%96%E9%94%AE%E5%80%BC%0A%20%20%20%20%20%20%20%20source%2C%20data%20%3D%20rediscli.blpop(%E2%80%9C%E9%A1%B9%E7%9B%AE%E5%90%8D%3Aitems%22)%0A%20%20%20%20%20%20%20%20data%20%3D%20data.decode('utf-8')%0A%20%20%20%20%20%20%20%20item%20%3D%20json.loads(data)%0A%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20sheet.insert(item)%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20(%22Processing%3Ainsert%20successed%22%20%25%20item)%0A%20%20%20%20%20%20%20%20except%20Exception%20as%20err%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print%20(%22err%20procesing%3A%20%25r%22%20%25%20item)%0A%0Aif%20__name__%20%3D%3D%20'__main__'%3A%0A%20%20%20%20main()%0A%60%60%60%0A%0A%23%23%23%23%20**%E5%B0%86%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA%E5%AD%98%E5%85%A5%20MySQL**%0A%E9%A6%96%E5%85%88%E5%90%AF%E5%8A%A8mysql%0A%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E8%A1%A8%0A%60%60%60%0A%23%20-*-%20coding%3A%20utf-8%20-*-%0A%0Aimport%20json%0Aimport%20redis%0Aimport%20pymysql%0A%0Adef%20main()%3A%0A%20%20%20%20%23%20%E6%8C%87%E5%AE%9Aredis%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%A1%E6%81%AF%0A%20%20%20%20rediscli%20%3D%20redis.StrictRedis(host%3D'localhost'%2C%20port%20%3D%206379%2C%20db%20%3D%200)%0A%20%20%20%20%23%20%E6%8C%87%E5%AE%9Amysql%E6%95%B0%E6%8D%AE%E5%BA%93%0A%20%20%20%20mysqlcli%20%3D%20pymysql.connect(host%3D'localhost'%2C%20user%3D'%E7%94%A8%E6%88%B7'%2C%20passwd%3D'%E5%AF%86%E7%A0%81'%2C%20db%20%3D%20'%E6%95%B0%E6%8D%AE%E5%BA%93'%2C%20port%3D3306%2C%20charset%3D'utf8')%0A%20%20%20%20%23%20%E4%BD%BF%E7%94%A8cursor()%E6%96%B9%E6%B3%95%E8%8E%B7%E5%8F%96%E6%93%8D%E4%BD%9C%E6%B8%B8%E6%A0%87%0A%20%20%20%20cur%20%3D%20mysqlcli.cursor()%0A%0A%20%20%20%20while%20True%3A%0A%20%20%20%20%20%20%20%20%23%20FIFO%E6%A8%A1%E5%BC%8F%E4%B8%BA%20blpop%EF%BC%8CLIFO%E6%A8%A1%E5%BC%8F%E4%B8%BA%20brpop%EF%BC%8C%E8%8E%B7%E5%8F%96%E9%94%AE%E5%80%BC%0A%20%20%20%20%20%20%20%20source%2C%20data%20%3D%20rediscli.blpop(%22redis%E4%B8%AD%E5%AF%B9%E5%BA%94%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9%3Aitems%22)%0A%20%20%20%20%20%20%20%20item%20%3D%20json.loads(data.decode('utf-8'))%0A%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20%E4%BD%BF%E7%94%A8execute%E6%96%B9%E6%B3%95%E6%89%A7%E8%A1%8CSQL%20INSERT%E8%AF%AD%E5%8F%A5%0A%20%20%20%20%20%20%20%20%20%20%20%20cur.execute(%22sql%E8%AF%AD%E5%8F%A5%22%EF%BC%8C%5B'%E6%95%B0%E6%8D%AE'%2C....%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20%E6%8F%90%E4%BA%A4sql%E4%BA%8B%E5%8A%A1%0A%20%20%20%20%20%20%20%20%20%20%20%20mysqlcli.commit()%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22inserted%20successed%22)%0A%20%20%20%20%20%20%20%20except%20Exception%20as%20err%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%E6%8F%92%E5%85%A5%E5%A4%B1%E8%B4%A5%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22Mysql%20Error%22%2Cerr)%0A%20%20%20%20%20%20%20%20%20%20%20%20mysqlcli.rollback()%0A%0Aif%20__name__%20%3D%3D%20'__main__'%3A%0A%20%20%20%20main()%0A%60%60%60</center></body></html>