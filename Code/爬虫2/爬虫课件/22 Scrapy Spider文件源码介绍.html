<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.0.5 (458014)"/><meta name="altitude" content="36"/><meta name="author" content="李居豪"/><meta name="created" content="2019-05-29 13:54:55 +0000"/><meta name="latitude" content="39.63155600945159"/><meta name="longitude" content="116.0504260503393"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2019-05-29 14:58:05 +0000"/><meta name="content-class" content="yinxiang.markdown"/><title>22 Scrapy Spider文件源码介绍</title></head><body><div style="font-size: 14px; margin: 0; padding: 0; width: 100%;"><p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">Spider类定义了如何爬取某个(或某些)网站。包括了爬取的动作(例如:是否跟进链接)以及如何从网页的内容中提取结构化数据(爬取item)。 换句话说，Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">scrapy.Spider</strong>是最基本的类，所有编写的爬虫必须继承这个类。</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">主要用到的函数及调用顺序为：</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">init</strong>()</strong> : 初始化爬虫名字和start_urls列表</p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">start_requests()</strong> 调用<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">make_requests_from url()</strong>:生成<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">Requests</strong>对象交给<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">Scrapy下载</strong>并返回<strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">response</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">parse()</strong>:</p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">解析response，并返回Item或Requests（需指定回调函数）。</li>
<li style="line-height: 160%; box-sizing: content-box; position: relative;">Item传给Item pipline持久化 ， 而Requests交由Scrapy下载，并由指定的回调函数处理（默认parse())，一直进行循环，直到处理完所有的数据为止。</li>
</ul>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">源码参考</strong></h4>
<h4 style="line-height: 160%; box-sizing: content-box; font-size: 20px; color: #333;">所有爬虫的基类，用户定义的爬虫必须从这个类继承</h4>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">class Spider(object_ref):

    #定义spider名字的字符串(string)。spider的名字定义了Scrapy如何定位(并初始化)spider，所以其必须是唯一的。
    #name是spider最重要的属性，而且是必须的。
    #一般做法是以该网站(domain)(加或不加 后缀 )来命名spider。 例如，如果spider爬取 mywebsite.com ，该spider通常会被命名为 mywebsite
    name = None

    #初始化，提取爬虫名字，start_ruls
    def __init__(self, name=None, **kwargs):
        if name is not None:
            self.name = name
        # 如果爬虫没有名字，中断后续操作则报错
        elif not getattr(self, 'name', None):
            raise ValueError("%s must have a name" % type(self).__name__)

        # python 对象或类型通过内置成员__dict__来存储成员信息
        self.__dict__.update(kwargs)

        #URL列表。当没有指定的URL时，spider将从该列表中开始
        进行爬取。 因此，第一个被获取到的页面的URL将是该列表
        之一。 后续的URL将会从获取到的数据中提取。
        if not hasattr(self, 'start_urls'):
            self.start_urls = []

    # 打印Scrapy执行后的log信息
    def log(self, message, level=log.DEBUG, **kw):
        log.msg(message, spider=self, level=level, **kw)

    # 判断对象object的属性是否存在
    def set_crawler(self, crawler):
        assert not hasattr(self, '_crawler'), "Spider already bounded to %s" % crawler
        self._crawler = crawler

    @property
    def crawler(self):
        assert hasattr(self, '_crawler'), "Spider not bounded to any crawler"
        return self._crawler

    @property
    def settings(self):
        return self.crawler.settings

    #该方法将读取start_urls内的地址，并为每一个地址
    生成一个Request对象，交给Scrapy下载并返回Response
    #该方法仅调用一次
    def start_requests(self):
        for url in self.start_urls:
            yield self.make_requests_from_url(url)

    #start_requests()中调用，实际生成Request的函数。
    #Request对象默认的回调函数为parse()，提交的方式为get
    def make_requests_from_url(self, url):
        return Request(url, dont_filter=True)

    #默认的Request对象回调函数，处理返回的response。
    #生成Item或者Request对象。用户必须实现这个类
    def parse(self, response):
        raise NotImplementedError

    @classmethod
    def handles_request(cls, request):
        return url_is_from_spider(request.url, cls)

    def __str__(self):
        return "&lt;%s %r at 0x%0x&gt;" % (type(self).__name__, self.name, id(self))

    __repr__ = __str__
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">主要属性和方法</strong></p>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">name</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">    定义spider名字的字符串。

    例如，如果spider爬取 mywebsite.com ，该spider通常会被命名为 mywebsite
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">allowed_domains</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">    包含了spider允许爬取的域名(domain)的列表，可选。
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">start_urls</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">    初始URL元组/列表。当没有制定特定的URL时，spider将从该列
    表中开始进行爬取。
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">start_requests(self)</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">    该方法必须返回一个可迭代对象(iterable)。该对象包含了
    spider用于爬取（默认实现是使用 start_urls 的url）的第
    一个Request。

    当spider启动爬取并且未指定start_urls时，该方法被调用。
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">parse(self, response)</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">    当请求url返回网页没有指定回调函数时，默认的Request对象回
    调函数。用来处理网页返回的response，以及生成Item或者
    Request对象。
</code></pre>
<ul style="line-height: 160%; box-sizing: content-box; display: block; list-style-type: disc; padding-left: 30px; margin: 6px 0 10px; color: #333;">
<li style="line-height: 160%; box-sizing: content-box; position: relative;">log(self, message[, level, component])</li>
</ul>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">    使用 scrapy.log.msg() 方法记录(log)message。 更多数
    据请参见 logging
</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">补充启动方式二</strong>：</p>
<pre style="line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; margin: 2px 0 8px; background-color: #f5f7f8;"><code style="display: block; overflow-x: auto; background: #1e1e1e; line-height: 160%; box-sizing: content-box; border: 0; border-radius: 0; letter-spacing: -.3px; padding: 18px; color: #f4f4f4; white-space: pre-wrap;">在开发过程中我们避免不了要调试程序，那么我们需要在工程中添加main.py 文件
import os
import sys
from scrapy.cmdline import execute

#设置工程目录
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
#这里我们可以打印出来可以查看输出的是什么，便于理解为什么这么写
print(os.path.abspath(__file__))
print(os.path.dirname(os.path.abspath(__file__)))

#启动爬虫
execute(["scrapy","crawl","爬虫名称"])

</code></pre>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;"><strong style="line-height: 160%; box-sizing: content-box; font-weight: 700;">思考</strong></p>
<p style="line-height: 160%; box-sizing: content-box; margin: 10px 0; color: #333;">请思考 parse()方法的工作机制：</p>
<ol style="line-height: 160%; box-sizing: content-box; display: block; padding-left: 30px; margin: 6px 0 10px; color: #333; list-style-type: decimal;">
<li style="line-height: 160%; box-sizing: content-box;">因为使用的yield，而不是return。parse函数将会被当做一个生成器使用。scrapy会逐一获取parse方法中生成的结果，并判断该结果是一个什么样的类型；</li>
<li style="line-height: 160%; box-sizing: content-box;">如果是request则加入爬取队列，如果是item类型则使用pipeline处理，其他类型则返回错误信息。</li>
<li style="line-height: 160%; box-sizing: content-box;">scrapy取到第一部分的request不会立马就去发送这个request，只是把这个request放到队列里，然后接着从生成器里获取；</li>
<li style="line-height: 160%; box-sizing: content-box;">取尽第一部分的request，然后再获取第二部分的item，取到item了，就会放到对应的pipeline里处理；</li>
<li style="line-height: 160%; box-sizing: content-box;">parse()方法作为回调函数(callback)赋值给了Request，指定parse()方法来处理这些请求 scrapy.Request(url, callback=self.parse)</li>
<li style="line-height: 160%; box-sizing: content-box;">Request对象经过调度，执行生成 scrapy.http.response()的响应对象，并送回给parse()方法，直到调度器中没有Request（递归的思路）</li>
<li style="line-height: 160%; box-sizing: content-box;">取尽之后，parse()工作结束，引擎再根据队列和pipelines中的内容去执行相应的操作；</li>
<li style="line-height: 160%; box-sizing: content-box;">程序在取得各个页面的items前，会先处理完之前所有的request队列里的请求，然后再提取items。</li>
<li style="line-height: 160%; box-sizing: content-box;">这一切的一切，Scrapy引擎和调度器将负责到底。</li>
</ol>
</div><center style="display:none !important;visibility:collapse !important;height:0 !important;white-space:nowrap;width:100%;overflow:hidden">Spider%E7%B1%BB%E5%AE%9A%E4%B9%89%E4%BA%86%E5%A6%82%E4%BD%95%E7%88%AC%E5%8F%96%E6%9F%90%E4%B8%AA(%E6%88%96%E6%9F%90%E4%BA%9B)%E7%BD%91%E7%AB%99%E3%80%82%E5%8C%85%E6%8B%AC%E4%BA%86%E7%88%AC%E5%8F%96%E7%9A%84%E5%8A%A8%E4%BD%9C(%E4%BE%8B%E5%A6%82%3A%E6%98%AF%E5%90%A6%E8%B7%9F%E8%BF%9B%E9%93%BE%E6%8E%A5)%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E4%BB%8E%E7%BD%91%E9%A1%B5%E7%9A%84%E5%86%85%E5%AE%B9%E4%B8%AD%E6%8F%90%E5%8F%96%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE(%E7%88%AC%E5%8F%96item)%E3%80%82%20%E6%8D%A2%E5%8F%A5%E8%AF%9D%E8%AF%B4%EF%BC%8CSpider%E5%B0%B1%E6%98%AF%E6%82%A8%E5%AE%9A%E4%B9%89%E7%88%AC%E5%8F%96%E7%9A%84%E5%8A%A8%E4%BD%9C%E5%8F%8A%E5%88%86%E6%9E%90%E6%9F%90%E4%B8%AA%E7%BD%91%E9%A1%B5(%E6%88%96%E8%80%85%E6%98%AF%E6%9C%89%E4%BA%9B%E7%BD%91%E9%A1%B5)%E7%9A%84%E5%9C%B0%E6%96%B9%E3%80%82%0A%0A**scrapy.Spider**%E6%98%AF%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84%E7%B1%BB%EF%BC%8C%E6%89%80%E6%9C%89%E7%BC%96%E5%86%99%E7%9A%84%E7%88%AC%E8%99%AB%E5%BF%85%E9%A1%BB%E7%BB%A7%E6%89%BF%E8%BF%99%E4%B8%AA%E7%B1%BB%E3%80%82%0A%0A%E4%B8%BB%E8%A6%81%E7%94%A8%E5%88%B0%E7%9A%84%E5%87%BD%E6%95%B0%E5%8F%8A%E8%B0%83%E7%94%A8%E9%A1%BA%E5%BA%8F%E4%B8%BA%EF%BC%9A%0A%0A**__init__()**%20%3A%20%E5%88%9D%E5%A7%8B%E5%8C%96%E7%88%AC%E8%99%AB%E5%90%8D%E5%AD%97%E5%92%8Cstart_urls%E5%88%97%E8%A1%A8%0A%0A**start_requests()**%20%E8%B0%83%E7%94%A8**make_requests_from%20url()**%3A%E7%94%9F%E6%88%90**Requests**%E5%AF%B9%E8%B1%A1%E4%BA%A4%E7%BB%99**Scrapy%E4%B8%8B%E8%BD%BD**%E5%B9%B6%E8%BF%94%E5%9B%9E**response**%0A%0A**parse()**%3A%20%0A-%20%E8%A7%A3%E6%9E%90response%EF%BC%8C%E5%B9%B6%E8%BF%94%E5%9B%9EItem%E6%88%96Requests%EF%BC%88%E9%9C%80%E6%8C%87%E5%AE%9A%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%EF%BC%89%E3%80%82%0A-%20Item%E4%BC%A0%E7%BB%99Item%20pipline%E6%8C%81%E4%B9%85%E5%8C%96%20%EF%BC%8C%20%E8%80%8CRequests%E4%BA%A4%E7%94%B1Scrapy%E4%B8%8B%E8%BD%BD%EF%BC%8C%E5%B9%B6%E7%94%B1%E6%8C%87%E5%AE%9A%E7%9A%84%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E5%A4%84%E7%90%86%EF%BC%88%E9%BB%98%E8%AE%A4parse())%EF%BC%8C%E4%B8%80%E7%9B%B4%E8%BF%9B%E8%A1%8C%E5%BE%AA%E7%8E%AF%EF%BC%8C%E7%9B%B4%E5%88%B0%E5%A4%84%E7%90%86%E5%AE%8C%E6%89%80%E6%9C%89%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%BA%E6%AD%A2%E3%80%82%0A%0A%0A%23%23%23%23%20**%E6%BA%90%E7%A0%81%E5%8F%82%E8%80%83**%0A%23%23%23%23%20%E6%89%80%E6%9C%89%E7%88%AC%E8%99%AB%E7%9A%84%E5%9F%BA%E7%B1%BB%EF%BC%8C%E7%94%A8%E6%88%B7%E5%AE%9A%E4%B9%89%E7%9A%84%E7%88%AC%E8%99%AB%E5%BF%85%E9%A1%BB%E4%BB%8E%E8%BF%99%E4%B8%AA%E7%B1%BB%E7%BB%A7%E6%89%BF%0A%0A%60%60%60%0Aclass%20Spider(object_ref)%3A%0A%0A%20%20%20%20%23%E5%AE%9A%E4%B9%89spider%E5%90%8D%E5%AD%97%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2(string)%E3%80%82spider%E7%9A%84%E5%90%8D%E5%AD%97%E5%AE%9A%E4%B9%89%E4%BA%86Scrapy%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D(%E5%B9%B6%E5%88%9D%E5%A7%8B%E5%8C%96)spider%EF%BC%8C%E6%89%80%E4%BB%A5%E5%85%B6%E5%BF%85%E9%A1%BB%E6%98%AF%E5%94%AF%E4%B8%80%E7%9A%84%E3%80%82%0A%20%20%20%20%23name%E6%98%AFspider%E6%9C%80%E9%87%8D%E8%A6%81%E7%9A%84%E5%B1%9E%E6%80%A7%EF%BC%8C%E8%80%8C%E4%B8%94%E6%98%AF%E5%BF%85%E9%A1%BB%E7%9A%84%E3%80%82%0A%20%20%20%20%23%E4%B8%80%E8%88%AC%E5%81%9A%E6%B3%95%E6%98%AF%E4%BB%A5%E8%AF%A5%E7%BD%91%E7%AB%99(domain)(%E5%8A%A0%E6%88%96%E4%B8%8D%E5%8A%A0%20%E5%90%8E%E7%BC%80%20)%E6%9D%A5%E5%91%BD%E5%90%8Dspider%E3%80%82%20%E4%BE%8B%E5%A6%82%EF%BC%8C%E5%A6%82%E6%9E%9Cspider%E7%88%AC%E5%8F%96%20mywebsite.com%20%EF%BC%8C%E8%AF%A5spider%E9%80%9A%E5%B8%B8%E4%BC%9A%E8%A2%AB%E5%91%BD%E5%90%8D%E4%B8%BA%20mywebsite%0A%20%20%20%20name%20%3D%20None%0A%0A%20%20%20%20%23%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%8C%E6%8F%90%E5%8F%96%E7%88%AC%E8%99%AB%E5%90%8D%E5%AD%97%EF%BC%8Cstart_ruls%0A%20%20%20%20def%20__init__(self%2C%20name%3DNone%2C%20**kwargs)%3A%0A%20%20%20%20%20%20%20%20if%20name%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.name%20%3D%20name%0A%20%20%20%20%20%20%20%20%23%20%E5%A6%82%E6%9E%9C%E7%88%AC%E8%99%AB%E6%B2%A1%E6%9C%89%E5%90%8D%E5%AD%97%EF%BC%8C%E4%B8%AD%E6%96%AD%E5%90%8E%E7%BB%AD%E6%93%8D%E4%BD%9C%E5%88%99%E6%8A%A5%E9%94%99%0A%20%20%20%20%20%20%20%20elif%20not%20getattr(self%2C%20'name'%2C%20None)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20raise%20ValueError(%22%25s%20must%20have%20a%20name%22%20%25%20type(self).__name__)%0A%0A%20%20%20%20%20%20%20%20%23%20python%20%E5%AF%B9%E8%B1%A1%E6%88%96%E7%B1%BB%E5%9E%8B%E9%80%9A%E8%BF%87%E5%86%85%E7%BD%AE%E6%88%90%E5%91%98__dict__%E6%9D%A5%E5%AD%98%E5%82%A8%E6%88%90%E5%91%98%E4%BF%A1%E6%81%AF%0A%20%20%20%20%20%20%20%20self.__dict__.update(kwargs)%0A%0A%20%20%20%20%20%20%20%20%23URL%E5%88%97%E8%A1%A8%E3%80%82%E5%BD%93%E6%B2%A1%E6%9C%89%E6%8C%87%E5%AE%9A%E7%9A%84URL%E6%97%B6%EF%BC%8Cspider%E5%B0%86%E4%BB%8E%E8%AF%A5%E5%88%97%E8%A1%A8%E4%B8%AD%E5%BC%80%E5%A7%8B%0A%20%20%20%20%20%20%20%20%E8%BF%9B%E8%A1%8C%E7%88%AC%E5%8F%96%E3%80%82%20%E5%9B%A0%E6%AD%A4%EF%BC%8C%E7%AC%AC%E4%B8%80%E4%B8%AA%E8%A2%AB%E8%8E%B7%E5%8F%96%E5%88%B0%E7%9A%84%E9%A1%B5%E9%9D%A2%E7%9A%84URL%E5%B0%86%E6%98%AF%E8%AF%A5%E5%88%97%E8%A1%A8%0A%20%20%20%20%20%20%20%20%E4%B9%8B%E4%B8%80%E3%80%82%20%E5%90%8E%E7%BB%AD%E7%9A%84URL%E5%B0%86%E4%BC%9A%E4%BB%8E%E8%8E%B7%E5%8F%96%E5%88%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%AD%E6%8F%90%E5%8F%96%E3%80%82%0A%20%20%20%20%20%20%20%20if%20not%20hasattr(self%2C%20'start_urls')%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.start_urls%20%3D%20%5B%5D%0A%0A%20%20%20%20%23%20%E6%89%93%E5%8D%B0Scrapy%E6%89%A7%E8%A1%8C%E5%90%8E%E7%9A%84log%E4%BF%A1%E6%81%AF%0A%20%20%20%20def%20log(self%2C%20message%2C%20level%3Dlog.DEBUG%2C%20**kw)%3A%0A%20%20%20%20%20%20%20%20log.msg(message%2C%20spider%3Dself%2C%20level%3Dlevel%2C%20**kw)%0A%0A%20%20%20%20%23%20%E5%88%A4%E6%96%AD%E5%AF%B9%E8%B1%A1object%E7%9A%84%E5%B1%9E%E6%80%A7%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8%0A%20%20%20%20def%20set_crawler(self%2C%20crawler)%3A%0A%20%20%20%20%20%20%20%20assert%20not%20hasattr(self%2C%20'_crawler')%2C%20%22Spider%20already%20bounded%20to%20%25s%22%20%25%20crawler%0A%20%20%20%20%20%20%20%20self._crawler%20%3D%20crawler%0A%0A%20%20%20%20%40property%0A%20%20%20%20def%20crawler(self)%3A%0A%20%20%20%20%20%20%20%20assert%20hasattr(self%2C%20'_crawler')%2C%20%22Spider%20not%20bounded%20to%20any%20crawler%22%0A%20%20%20%20%20%20%20%20return%20self._crawler%0A%0A%20%20%20%20%40property%0A%20%20%20%20def%20settings(self)%3A%0A%20%20%20%20%20%20%20%20return%20self.crawler.settings%0A%0A%20%20%20%20%23%E8%AF%A5%E6%96%B9%E6%B3%95%E5%B0%86%E8%AF%BB%E5%8F%96start_urls%E5%86%85%E7%9A%84%E5%9C%B0%E5%9D%80%EF%BC%8C%E5%B9%B6%E4%B8%BA%E6%AF%8F%E4%B8%80%E4%B8%AA%E5%9C%B0%E5%9D%80%0A%20%20%20%20%E7%94%9F%E6%88%90%E4%B8%80%E4%B8%AARequest%E5%AF%B9%E8%B1%A1%EF%BC%8C%E4%BA%A4%E7%BB%99Scrapy%E4%B8%8B%E8%BD%BD%E5%B9%B6%E8%BF%94%E5%9B%9EResponse%0A%20%20%20%20%23%E8%AF%A5%E6%96%B9%E6%B3%95%E4%BB%85%E8%B0%83%E7%94%A8%E4%B8%80%E6%AC%A1%0A%20%20%20%20def%20start_requests(self)%3A%0A%20%20%20%20%20%20%20%20for%20url%20in%20self.start_urls%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20yield%20self.make_requests_from_url(url)%0A%0A%20%20%20%20%23start_requests()%E4%B8%AD%E8%B0%83%E7%94%A8%EF%BC%8C%E5%AE%9E%E9%99%85%E7%94%9F%E6%88%90Request%E7%9A%84%E5%87%BD%E6%95%B0%E3%80%82%0A%20%20%20%20%23Request%E5%AF%B9%E8%B1%A1%E9%BB%98%E8%AE%A4%E7%9A%84%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E4%B8%BAparse()%EF%BC%8C%E6%8F%90%E4%BA%A4%E7%9A%84%E6%96%B9%E5%BC%8F%E4%B8%BAget%0A%20%20%20%20def%20make_requests_from_url(self%2C%20url)%3A%0A%20%20%20%20%20%20%20%20return%20Request(url%2C%20dont_filter%3DTrue)%0A%0A%20%20%20%20%23%E9%BB%98%E8%AE%A4%E7%9A%84Request%E5%AF%B9%E8%B1%A1%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%EF%BC%8C%E5%A4%84%E7%90%86%E8%BF%94%E5%9B%9E%E7%9A%84response%E3%80%82%0A%20%20%20%20%23%E7%94%9F%E6%88%90Item%E6%88%96%E8%80%85Request%E5%AF%B9%E8%B1%A1%E3%80%82%E7%94%A8%E6%88%B7%E5%BF%85%E9%A1%BB%E5%AE%9E%E7%8E%B0%E8%BF%99%E4%B8%AA%E7%B1%BB%0A%20%20%20%20def%20parse(self%2C%20response)%3A%0A%20%20%20%20%20%20%20%20raise%20NotImplementedError%0A%0A%20%20%20%20%40classmethod%0A%20%20%20%20def%20handles_request(cls%2C%20request)%3A%0A%20%20%20%20%20%20%20%20return%20url_is_from_spider(request.url%2C%20cls)%0A%0A%20%20%20%20def%20__str__(self)%3A%0A%20%20%20%20%20%20%20%20return%20%22%3C%25s%20%25r%20at%200x%250x%3E%22%20%25%20(type(self).__name__%2C%20self.name%2C%20id(self))%0A%0A%20%20%20%20__repr__%20%3D%20__str__%0A%60%60%60%0A%0A**%E4%B8%BB%E8%A6%81%E5%B1%9E%E6%80%A7%E5%92%8C%E6%96%B9%E6%B3%95**%0A%0A-%20name%0A%60%60%60%0A%20%20%20%20%E5%AE%9A%E4%B9%89spider%E5%90%8D%E5%AD%97%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E3%80%82%0A%0A%20%20%20%20%E4%BE%8B%E5%A6%82%EF%BC%8C%E5%A6%82%E6%9E%9Cspider%E7%88%AC%E5%8F%96%20mywebsite.com%20%EF%BC%8C%E8%AF%A5spider%E9%80%9A%E5%B8%B8%E4%BC%9A%E8%A2%AB%E5%91%BD%E5%90%8D%E4%B8%BA%20mywebsite%0A%60%60%60%0A%0A-%20allowed_domains%0A%60%60%60%0A%20%20%20%20%E5%8C%85%E5%90%AB%E4%BA%86spider%E5%85%81%E8%AE%B8%E7%88%AC%E5%8F%96%E7%9A%84%E5%9F%9F%E5%90%8D(domain)%E7%9A%84%E5%88%97%E8%A1%A8%EF%BC%8C%E5%8F%AF%E9%80%89%E3%80%82%0A%60%60%60%0A%0A-%20start_urls%0A%60%60%60%0A%20%20%20%20%E5%88%9D%E5%A7%8BURL%E5%85%83%E7%BB%84%2F%E5%88%97%E8%A1%A8%E3%80%82%E5%BD%93%E6%B2%A1%E6%9C%89%E5%88%B6%E5%AE%9A%E7%89%B9%E5%AE%9A%E7%9A%84URL%E6%97%B6%EF%BC%8Cspider%E5%B0%86%E4%BB%8E%E8%AF%A5%E5%88%97%0A%20%20%20%20%E8%A1%A8%E4%B8%AD%E5%BC%80%E5%A7%8B%E8%BF%9B%E8%A1%8C%E7%88%AC%E5%8F%96%E3%80%82%0A%60%60%60%0A-%20start_requests(self)%0A%60%60%60%0A%20%20%20%20%E8%AF%A5%E6%96%B9%E6%B3%95%E5%BF%85%E9%A1%BB%E8%BF%94%E5%9B%9E%E4%B8%80%E4%B8%AA%E5%8F%AF%E8%BF%AD%E4%BB%A3%E5%AF%B9%E8%B1%A1(iterable)%E3%80%82%E8%AF%A5%E5%AF%B9%E8%B1%A1%E5%8C%85%E5%90%AB%E4%BA%86%0A%20%20%20%20spider%E7%94%A8%E4%BA%8E%E7%88%AC%E5%8F%96%EF%BC%88%E9%BB%98%E8%AE%A4%E5%AE%9E%E7%8E%B0%E6%98%AF%E4%BD%BF%E7%94%A8%20start_urls%20%E7%9A%84url%EF%BC%89%E7%9A%84%E7%AC%AC%0A%20%20%20%20%E4%B8%80%E4%B8%AARequest%E3%80%82%0A%0A%20%20%20%20%E5%BD%93spider%E5%90%AF%E5%8A%A8%E7%88%AC%E5%8F%96%E5%B9%B6%E4%B8%94%E6%9C%AA%E6%8C%87%E5%AE%9Astart_urls%E6%97%B6%EF%BC%8C%E8%AF%A5%E6%96%B9%E6%B3%95%E8%A2%AB%E8%B0%83%E7%94%A8%E3%80%82%0A%60%60%60%0A-%20parse(self%2C%20response)%0A%60%60%60%0A%20%20%20%20%E5%BD%93%E8%AF%B7%E6%B1%82url%E8%BF%94%E5%9B%9E%E7%BD%91%E9%A1%B5%E6%B2%A1%E6%9C%89%E6%8C%87%E5%AE%9A%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0%E6%97%B6%EF%BC%8C%E9%BB%98%E8%AE%A4%E7%9A%84Request%E5%AF%B9%E8%B1%A1%E5%9B%9E%0A%20%20%20%20%E8%B0%83%E5%87%BD%E6%95%B0%E3%80%82%E7%94%A8%E6%9D%A5%E5%A4%84%E7%90%86%E7%BD%91%E9%A1%B5%E8%BF%94%E5%9B%9E%E7%9A%84response%EF%BC%8C%E4%BB%A5%E5%8F%8A%E7%94%9F%E6%88%90Item%E6%88%96%E8%80%85%0A%20%20%20%20Request%E5%AF%B9%E8%B1%A1%E3%80%82%0A%60%60%60%0A-%20log(self%2C%20message%5B%2C%20level%2C%20component%5D)%0A%60%60%60%0A%20%20%20%20%E4%BD%BF%E7%94%A8%20scrapy.log.msg()%20%E6%96%B9%E6%B3%95%E8%AE%B0%E5%BD%95(log)message%E3%80%82%20%E6%9B%B4%E5%A4%9A%E6%95%B0%0A%20%20%20%20%E6%8D%AE%E8%AF%B7%E5%8F%82%E8%A7%81%20logging%0A%60%60%60%0A%0A**%E8%A1%A5%E5%85%85%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F%E4%BA%8C**%EF%BC%9A%0A%60%60%60%0A%E5%9C%A8%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E6%88%91%E4%BB%AC%E9%81%BF%E5%85%8D%E4%B8%8D%E4%BA%86%E8%A6%81%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F%EF%BC%8C%E9%82%A3%E4%B9%88%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81%E5%9C%A8%E5%B7%A5%E7%A8%8B%E4%B8%AD%E6%B7%BB%E5%8A%A0main.py%20%E6%96%87%E4%BB%B6%0Aimport%20os%0Aimport%20sys%0Afrom%20scrapy.cmdline%20import%20execute%0A%0A%23%E8%AE%BE%E7%BD%AE%E5%B7%A5%E7%A8%8B%E7%9B%AE%E5%BD%95%0Asys.path.append(os.path.dirname(os.path.abspath(__file__)))%0A%23%E8%BF%99%E9%87%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E6%89%93%E5%8D%B0%E5%87%BA%E6%9D%A5%E5%8F%AF%E4%BB%A5%E6%9F%A5%E7%9C%8B%E8%BE%93%E5%87%BA%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%8C%E4%BE%BF%E4%BA%8E%E7%90%86%E8%A7%A3%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%86%99%0Aprint(os.path.abspath(__file__))%0Aprint(os.path.dirname(os.path.abspath(__file__)))%0A%0A%23%E5%90%AF%E5%8A%A8%E7%88%AC%E8%99%AB%0Aexecute(%5B%22scrapy%22%2C%22crawl%22%2C%22%E7%88%AC%E8%99%AB%E5%90%8D%E7%A7%B0%22%5D)%0A%0A%60%60%60%0A%0A**%E6%80%9D%E8%80%83**%0A%0A%E8%AF%B7%E6%80%9D%E8%80%83%20parse()%E6%96%B9%E6%B3%95%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%9A%0A%0A1.%20%E5%9B%A0%E4%B8%BA%E4%BD%BF%E7%94%A8%E7%9A%84yield%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AFreturn%E3%80%82parse%E5%87%BD%E6%95%B0%E5%B0%86%E4%BC%9A%E8%A2%AB%E5%BD%93%E5%81%9A%E4%B8%80%E4%B8%AA%E7%94%9F%E6%88%90%E5%99%A8%E4%BD%BF%E7%94%A8%E3%80%82scrapy%E4%BC%9A%E9%80%90%E4%B8%80%E8%8E%B7%E5%8F%96parse%E6%96%B9%E6%B3%95%E4%B8%AD%E7%94%9F%E6%88%90%E7%9A%84%E7%BB%93%E6%9E%9C%EF%BC%8C%E5%B9%B6%E5%88%A4%E6%96%AD%E8%AF%A5%E7%BB%93%E6%9E%9C%E6%98%AF%E4%B8%80%E4%B8%AA%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E7%B1%BB%E5%9E%8B%EF%BC%9B%0A2.%20%E5%A6%82%E6%9E%9C%E6%98%AFrequest%E5%88%99%E5%8A%A0%E5%85%A5%E7%88%AC%E5%8F%96%E9%98%9F%E5%88%97%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%98%AFitem%E7%B1%BB%E5%9E%8B%E5%88%99%E4%BD%BF%E7%94%A8pipeline%E5%A4%84%E7%90%86%EF%BC%8C%E5%85%B6%E4%BB%96%E7%B1%BB%E5%9E%8B%E5%88%99%E8%BF%94%E5%9B%9E%E9%94%99%E8%AF%AF%E4%BF%A1%E6%81%AF%E3%80%82%0A3.%20scrapy%E5%8F%96%E5%88%B0%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E7%9A%84request%E4%B8%8D%E4%BC%9A%E7%AB%8B%E9%A9%AC%E5%B0%B1%E5%8E%BB%E5%8F%91%E9%80%81%E8%BF%99%E4%B8%AArequest%EF%BC%8C%E5%8F%AA%E6%98%AF%E6%8A%8A%E8%BF%99%E4%B8%AArequest%E6%94%BE%E5%88%B0%E9%98%9F%E5%88%97%E9%87%8C%EF%BC%8C%E7%84%B6%E5%90%8E%E6%8E%A5%E7%9D%80%E4%BB%8E%E7%94%9F%E6%88%90%E5%99%A8%E9%87%8C%E8%8E%B7%E5%8F%96%EF%BC%9B%0A4.%20%E5%8F%96%E5%B0%BD%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E7%9A%84request%EF%BC%8C%E7%84%B6%E5%90%8E%E5%86%8D%E8%8E%B7%E5%8F%96%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%E7%9A%84item%EF%BC%8C%E5%8F%96%E5%88%B0item%E4%BA%86%EF%BC%8C%E5%B0%B1%E4%BC%9A%E6%94%BE%E5%88%B0%E5%AF%B9%E5%BA%94%E7%9A%84pipeline%E9%87%8C%E5%A4%84%E7%90%86%EF%BC%9B%0A5.%20parse()%E6%96%B9%E6%B3%95%E4%BD%9C%E4%B8%BA%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0(callback)%E8%B5%8B%E5%80%BC%E7%BB%99%E4%BA%86Request%EF%BC%8C%E6%8C%87%E5%AE%9Aparse()%E6%96%B9%E6%B3%95%E6%9D%A5%E5%A4%84%E7%90%86%E8%BF%99%E4%BA%9B%E8%AF%B7%E6%B1%82%20scrapy.Request(url%2C%20callback%3Dself.parse)%0A6.%20Request%E5%AF%B9%E8%B1%A1%E7%BB%8F%E8%BF%87%E8%B0%83%E5%BA%A6%EF%BC%8C%E6%89%A7%E8%A1%8C%E7%94%9F%E6%88%90%20scrapy.http.response()%E7%9A%84%E5%93%8D%E5%BA%94%E5%AF%B9%E8%B1%A1%EF%BC%8C%E5%B9%B6%E9%80%81%E5%9B%9E%E7%BB%99parse()%E6%96%B9%E6%B3%95%EF%BC%8C%E7%9B%B4%E5%88%B0%E8%B0%83%E5%BA%A6%E5%99%A8%E4%B8%AD%E6%B2%A1%E6%9C%89Request%EF%BC%88%E9%80%92%E5%BD%92%E7%9A%84%E6%80%9D%E8%B7%AF%EF%BC%89%0A7.%20%E5%8F%96%E5%B0%BD%E4%B9%8B%E5%90%8E%EF%BC%8Cparse()%E5%B7%A5%E4%BD%9C%E7%BB%93%E6%9D%9F%EF%BC%8C%E5%BC%95%E6%93%8E%E5%86%8D%E6%A0%B9%E6%8D%AE%E9%98%9F%E5%88%97%E5%92%8Cpipelines%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%E5%8E%BB%E6%89%A7%E8%A1%8C%E7%9B%B8%E5%BA%94%E7%9A%84%E6%93%8D%E4%BD%9C%EF%BC%9B%0A8.%20%E7%A8%8B%E5%BA%8F%E5%9C%A8%E5%8F%96%E5%BE%97%E5%90%84%E4%B8%AA%E9%A1%B5%E9%9D%A2%E7%9A%84items%E5%89%8D%EF%BC%8C%E4%BC%9A%E5%85%88%E5%A4%84%E7%90%86%E5%AE%8C%E4%B9%8B%E5%89%8D%E6%89%80%E6%9C%89%E7%9A%84request%E9%98%9F%E5%88%97%E9%87%8C%E7%9A%84%E8%AF%B7%E6%B1%82%EF%BC%8C%E7%84%B6%E5%90%8E%E5%86%8D%E6%8F%90%E5%8F%96items%E3%80%82%0A9.%20%E8%BF%99%E4%B8%80%E5%88%87%E7%9A%84%E4%B8%80%E5%88%87%EF%BC%8CScrapy%E5%BC%95%E6%93%8E%E5%92%8C%E8%B0%83%E5%BA%A6%E5%99%A8%E5%B0%86%E8%B4%9F%E8%B4%A3%E5%88%B0%E5%BA%95%E3%80%82%0A</center></body></html>